{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57c833a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cells': [{'cell_type': 'markdown',\n",
       "   'metadata': {},\n",
       "   'source': ['# Indonesia Heart Attack Prediction\\n',\n",
       "    '## Notebook 5: Feature Engineering\\n',\n",
       "    '\\n',\n",
       "    '---\\n',\n",
       "    '\\n',\n",
       "    '### Tahap 5 dari Data Science Life Cycle\\n',\n",
       "    '\\n',\n",
       "    'Pada tahap ini, kita akan:\\n',\n",
       "    '1. Create new features dari existing features\\n',\n",
       "    '2. Transform features untuk improve model performance\\n',\n",
       "    '3. Select important features\\n',\n",
       "    '4. Encode categorical variables\\n',\n",
       "    '5. Scale numerical features\\n',\n",
       "    '6. Prepare final dataset untuk modeling']},\n",
       "  {'cell_type': 'markdown',\n",
       "   'metadata': {},\n",
       "   'source': ['## 1. Import Libraries dan Load Data']},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': None,\n",
       "   'metadata': {},\n",
       "   'outputs': [],\n",
       "   'source': ['# Data manipulation\\n',\n",
       "    'import pandas as pd\\n',\n",
       "    'import numpy as np\\n',\n",
       "    '\\n',\n",
       "    '# Visualization\\n',\n",
       "    'import matplotlib.pyplot as plt\\n',\n",
       "    'import seaborn as sns\\n',\n",
       "    '\\n',\n",
       "    '# Feature engineering and selection\\n',\n",
       "    'from sklearn.preprocessing import LabelEncoder, StandardScaler\\n',\n",
       "    'from sklearn.feature_selection import SelectKBest, chi2, f_classif, mutual_info_classif\\n',\n",
       "    '\\n',\n",
       "    '# System utilities\\n',\n",
       "    'import sys\\n',\n",
       "    \"sys.path.append('../src')\\n\",\n",
       "    '\\n',\n",
       "    '# Import custom modules\\n',\n",
       "    'from feature_engineering import FeatureEngineer, get_high_correlation_features, feature_summary\\n',\n",
       "    'from data_preprocessing import DataPreprocessor\\n',\n",
       "    '\\n',\n",
       "    '# Settings\\n',\n",
       "    \"pd.set_option('display.max_columns', None)\\n\",\n",
       "    \"plt.style.use('seaborn-v0_8-whitegrid')\\n\",\n",
       "    \"sns.set_palette('husl')\\n\",\n",
       "    '\\n',\n",
       "    'import warnings\\n',\n",
       "    \"warnings.filterwarnings('ignore')\\n\",\n",
       "    '\\n',\n",
       "    'print(\"Libraries imported successfully!\")']},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': None,\n",
       "   'metadata': {},\n",
       "   'outputs': [],\n",
       "   'source': ['# Load cleaned data\\n',\n",
       "    \"df = pd.read_csv('../data/heart_attack_data_cleaned.csv')\\n\",\n",
       "    '\\n',\n",
       "    'print(f\"Original dataset shape: {df.shape}\")\\n',\n",
       "    'print(f\"Features: {df.shape[1]}\")\\n',\n",
       "    '\\n',\n",
       "    '# Initialize feature engineer\\n',\n",
       "    'fe = FeatureEngineer()']},\n",
       "  {'cell_type': 'markdown',\n",
       "   'metadata': {},\n",
       "   'source': ['## 2. Create New Features']},\n",
       "  {'cell_type': 'markdown',\n",
       "   'metadata': {},\n",
       "   'source': ['### 2.1 Age-based Features']},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': None,\n",
       "   'metadata': {},\n",
       "   'outputs': [],\n",
       "   'source': ['print(\"Creating age-based features...\")\\n',\n",
       "    'print(\"=\"*60)\\n',\n",
       "    '\\n',\n",
       "    '# Age groups\\n',\n",
       "    'df_engineered = fe.create_age_groups(df)\\n',\n",
       "    '\\n',\n",
       "    'print(\"\\\\nAge groups created:\")\\n',\n",
       "    \"print(df_engineered['age_group'].value_counts().sort_index())\"]},\n",
       "  {'cell_type': 'markdown',\n",
       "   'metadata': {},\n",
       "   'source': ['### 2.2 Blood Pressure Categories']},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': None,\n",
       "   'metadata': {},\n",
       "   'outputs': [],\n",
       "   'source': ['print(\"Creating blood pressure categories...\")\\n',\n",
       "    'print(\"=\"*60)\\n',\n",
       "    '\\n',\n",
       "    'df_engineered = fe.create_blood_pressure_category(df_engineered)\\n',\n",
       "    '\\n',\n",
       "    'print(\"\\\\nBlood pressure categories:\")\\n',\n",
       "    \"print(df_engineered['bp_category'].value_counts())\"]},\n",
       "  {'cell_type': 'markdown',\n",
       "   'metadata': {},\n",
       "   'source': ['### 2.3 Cholesterol Categories']},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': None,\n",
       "   'metadata': {},\n",
       "   'outputs': [],\n",
       "   'source': ['print(\"Creating cholesterol categories...\")\\n',\n",
       "    'print(\"=\"*60)\\n',\n",
       "    '\\n',\n",
       "    'df_engineered = fe.create_cholesterol_category(df_engineered)\\n',\n",
       "    '\\n',\n",
       "    'print(\"\\\\nCholesterol categories:\")\\n',\n",
       "    \"print(df_engineered['cholesterol_category'].value_counts())\"]},\n",
       "  {'cell_type': 'markdown',\n",
       "   'metadata': {},\n",
       "   'source': ['### 2.4 BMI Category']},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': None,\n",
       "   'metadata': {},\n",
       "   'outputs': [],\n",
       "   'source': ['print(\"Creating BMI categories...\")\\n',\n",
       "    'print(\"=\"*60)\\n',\n",
       "    '\\n',\n",
       "    'df_engineered = fe.create_bmi_category(df_engineered)\\n',\n",
       "    '\\n',\n",
       "    'print(\"\\\\nBMI categories:\")\\n',\n",
       "    \"print(df_engineered['bmi_category'].value_counts())\"]},\n",
       "  {'cell_type': 'markdown',\n",
       "   'metadata': {},\n",
       "   'source': ['### 2.5 Risk Score (Composite Feature)']},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': None,\n",
       "   'metadata': {},\n",
       "   'outputs': [],\n",
       "   'source': ['print(\"Creating composite risk score...\")\\n',\n",
       "    'print(\"=\"*60)\\n',\n",
       "    '\\n',\n",
       "    'df_engineered = fe.create_risk_score(df_engineered)\\n',\n",
       "    '\\n',\n",
       "    'print(\"\\\\nRisk score statistics:\")\\n',\n",
       "    \"print(df_engineered['risk_score'].describe())\\n\",\n",
       "    '\\n',\n",
       "    '# Visualize risk score distribution\\n',\n",
       "    'fig, axes = plt.subplots(1, 2, figsize=(14, 5))\\n',\n",
       "    '\\n',\n",
       "    '# Distribution\\n',\n",
       "    \"df_engineered['risk_score'].hist(bins=15, ax=axes[0], color='steelblue', edgecolor='black')\\n\",\n",
       "    \"axes[0].set_title('Risk Score Distribution', fontsize=12, fontweight='bold')\\n\",\n",
       "    \"axes[0].set_xlabel('Risk Score')\\n\",\n",
       "    \"axes[0].set_ylabel('Frequency')\\n\",\n",
       "    \"axes[0].axvline(df_engineered['risk_score'].mean(), color='red', linestyle='--',\\n\",\n",
       "    '               label=f\\'Mean: {df_engineered[\"risk_score\"].mean():.2f}\\')\\n',\n",
       "    'axes[0].legend()\\n',\n",
       "    'axes[0].grid(alpha=0.3)\\n',\n",
       "    '\\n',\n",
       "    '# Risk score vs heart attack\\n',\n",
       "    \"df_engineered.boxplot(column='risk_score', by='heart_attack', ax=axes[1])\\n\",\n",
       "    \"axes[1].set_title('Risk Score by Heart Attack Status')\\n\",\n",
       "    \"axes[1].set_xlabel('Heart Attack')\\n\",\n",
       "    \"axes[1].set_ylabel('Risk Score')\\n\",\n",
       "    \"axes[1].set_xticklabels(['No', 'Yes'])\\n\",\n",
       "    'plt.sca(axes[1])\\n',\n",
       "    \"plt.xticks([1, 2], ['No', 'Yes'])\\n\",\n",
       "    '\\n',\n",
       "    'plt.tight_layout()\\n',\n",
       "    'plt.show()\\n',\n",
       "    '\\n',\n",
       "    '# Calculate mean risk score by heart attack status\\n',\n",
       "    'print(\"\\\\nMean risk score by heart attack status:\")\\n',\n",
       "    \"print(df_engineered.groupby('heart_attack')['risk_score'].mean())\"]},\n",
       "  {'cell_type': 'markdown',\n",
       "   'metadata': {},\n",
       "   'source': ['### 2.6 Interaction Features']},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': None,\n",
       "   'metadata': {},\n",
       "   'outputs': [],\n",
       "   'source': ['print(\"Creating interaction features...\")\\n',\n",
       "    'print(\"=\"*60)\\n',\n",
       "    '\\n',\n",
       "    'df_engineered = fe.create_interaction_features(df_engineered)\\n',\n",
       "    '\\n',\n",
       "    'print(\"\\\\nNew interaction features created:\")\\n',\n",
       "    \"interaction_features = ['age_hypertension', 'age_diabetes', 'cholesterol_age', \\n\",\n",
       "    \"                       'bp_interaction', 'total_health_conditions']\\n\",\n",
       "    'for feat in interaction_features:\\n',\n",
       "    '    if feat in df_engineered.columns:\\n',\n",
       "    '        print(f\"  - {feat}\")']},\n",
       "  {'cell_type': 'markdown',\n",
       "   'metadata': {},\n",
       "   'source': ['## 3. Feature Engineering Summary']},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': None,\n",
       "   'metadata': {},\n",
       "   'outputs': [],\n",
       "   'source': ['print(\"Feature Engineering Summary:\")\\n',\n",
       "    'print(\"=\"*60)\\n',\n",
       "    '\\n',\n",
       "    'summary = feature_summary(df, df_engineered)\\n',\n",
       "    '\\n',\n",
       "    'print(f\"\\\\nOriginal features: {summary[\\'original_features\\']}\")\\n',\n",
       "    'print(f\"Engineered features: {summary[\\'engineered_features\\']}\")\\n',\n",
       "    'print(f\"New features created: {summary[\\'new_features_count\\']}\")\\n',\n",
       "    '\\n',\n",
       "    'print(f\"\\\\nList of new features:\")\\n',\n",
       "    \"for i, feat in enumerate(summary['new_features_list'], 1):\\n\",\n",
       "    '    print(f\"  {i}. {feat}\")']},\n",
       "  {'cell_type': 'markdown',\n",
       "   'metadata': {},\n",
       "   'source': ['## 4. Encode Categorical Variables']},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': None,\n",
       "   'metadata': {},\n",
       "   'outputs': [],\n",
       "   'source': ['print(\"Encoding categorical variables...\")\\n',\n",
       "    'print(\"=\"*60)\\n',\n",
       "    '\\n',\n",
       "    '# Identify categorical columns\\n',\n",
       "    \"categorical_cols = df_engineered.select_dtypes(include=['object']).columns.tolist()\\n\",\n",
       "    '\\n',\n",
       "    'print(f\"\\\\nCategorical columns to encode: {len(categorical_cols)}\")\\n',\n",
       "    'for col in categorical_cols:\\n',\n",
       "    '    print(f\"  - {col}\")\\n',\n",
       "    '\\n',\n",
       "    '# Initialize preprocessor for encoding\\n',\n",
       "    'preprocessor = DataPreprocessor()\\n',\n",
       "    '\\n',\n",
       "    '# Encode categorical variables\\n',\n",
       "    'df_encoded = preprocessor.encode_categorical(df_engineered, categorical_cols)\\n',\n",
       "    '\\n',\n",
       "    'print(\"\\\\n✓ Categorical variables encoded successfully!\")\\n',\n",
       "    'print(f\"\\\\nDataset shape after encoding: {df_encoded.shape}\")']},\n",
       "  {'cell_type': 'markdown',\n",
       "   'metadata': {},\n",
       "   'source': ['## 5. Feature Correlation Analysis']},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': None,\n",
       "   'metadata': {},\n",
       "   'outputs': [],\n",
       "   'source': ['print(\"Analyzing feature correlations with target...\")\\n',\n",
       "    'print(\"=\"*60)\\n',\n",
       "    '\\n',\n",
       "    '# Calculate correlation with heart_attack\\n',\n",
       "    \"correlations = df_encoded.corr()['heart_attack'].drop('heart_attack').sort_values(ascending=False)\\n\",\n",
       "    '\\n',\n",
       "    'print(\"\\\\nTop 20 features correlated with Heart Attack:\")\\n',\n",
       "    'print(correlations.head(20))\\n',\n",
       "    '\\n',\n",
       "    '# Visualize top correlations\\n',\n",
       "    'plt.figure(figsize=(12, 10))\\n',\n",
       "    'top_n = 20\\n',\n",
       "    'top_corr = correlations.head(top_n)\\n',\n",
       "    \"colors = ['green' if x > 0 else 'red' for x in top_corr]\\n\",\n",
       "    '\\n',\n",
       "    'plt.barh(range(len(top_corr)), top_corr.values, color=colors)\\n',\n",
       "    'plt.yticks(range(len(top_corr)), top_corr.index)\\n',\n",
       "    \"plt.xlabel('Correlation Coefficient', fontsize=12)\\n\",\n",
       "    \"plt.title(f'Top {top_n} Features Correlated with Heart Attack', fontsize=14, fontweight='bold')\\n\",\n",
       "    \"plt.axvline(x=0, color='black', linestyle='--', linewidth=0.8)\\n\",\n",
       "    \"plt.grid(axis='x', alpha=0.3)\\n\",\n",
       "    'plt.tight_layout()\\n',\n",
       "    'plt.show()']},\n",
       "  {'cell_type': 'markdown',\n",
       "   'metadata': {},\n",
       "   'source': ['## 6. Feature Selection']},\n",
       "  {'cell_type': 'markdown',\n",
       "   'metadata': {},\n",
       "   'source': ['### 6.1 Correlation-based Feature Selection']},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': None,\n",
       "   'metadata': {},\n",
       "   'outputs': [],\n",
       "   'source': ['print(\"Correlation-based Feature Selection:\")\\n',\n",
       "    'print(\"=\"*60)\\n',\n",
       "    '\\n',\n",
       "    '# Select features with correlation > threshold\\n',\n",
       "    'threshold = 0.05\\n',\n",
       "    \"selected_features_corr = fe.select_features_correlation(df_encoded, 'heart_attack', threshold=threshold)\\n\",\n",
       "    '\\n',\n",
       "    'print(f\"\\\\nFeatures selected (correlation > {threshold}): {len(selected_features_corr)}\")']},\n",
       "  {'cell_type': 'markdown',\n",
       "   'metadata': {},\n",
       "   'source': ['### 6.2 Univariate Feature Selection']},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': None,\n",
       "   'metadata': {},\n",
       "   'outputs': [],\n",
       "   'source': ['print(\"Univariate Feature Selection:\")\\n',\n",
       "    'print(\"=\"*60)\\n',\n",
       "    '\\n',\n",
       "    '# Prepare X and y\\n',\n",
       "    \"X = df_encoded.drop('heart_attack', axis=1)\\n\",\n",
       "    \"y = df_encoded['heart_attack']\\n\",\n",
       "    '\\n',\n",
       "    '# Select top K features using f_classif\\n',\n",
       "    'k = 20\\n',\n",
       "    \"selected_features_univariate, selector = fe.select_features_univariate(X, y, k=k, score_func='f_classif')\\n\",\n",
       "    '\\n',\n",
       "    'print(f\"\\\\nTop {k} features selected.\")']},\n",
       "  {'cell_type': 'markdown',\n",
       "   'metadata': {},\n",
       "   'source': ['### 6.3 Check Multicollinearity']},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': None,\n",
       "   'metadata': {},\n",
       "   'outputs': [],\n",
       "   'source': ['print(\"Checking for multicollinearity...\")\\n',\n",
       "    'print(\"=\"*60)\\n',\n",
       "    '\\n',\n",
       "    '# Find highly correlated features\\n',\n",
       "    'high_corr_pairs = get_high_correlation_features(df_encoded, threshold=0.8)\\n',\n",
       "    '\\n',\n",
       "    'if len(high_corr_pairs) > 0:\\n',\n",
       "    '    print(f\"\\\\nFound {len(high_corr_pairs)} pairs of highly correlated features (>0.8):\")\\n',\n",
       "    '    for pair in high_corr_pairs[:10]:  # Show first 10\\n',\n",
       "    '        print(f\"  {pair[0]} <-> {pair[1]}: {pair[2]:.3f}\")\\n',\n",
       "    '    \\n',\n",
       "    '    print(\"\\\\n⚠️  Consider removing one feature from each highly correlated pair.\")\\n',\n",
       "    'else:\\n',\n",
       "    '    print(\"\\\\n✓ No high multicollinearity detected.\")']},\n",
       "  {'cell_type': 'markdown',\n",
       "   'metadata': {},\n",
       "   'source': ['## 7. Prepare Final Feature Set']},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': None,\n",
       "   'metadata': {},\n",
       "   'outputs': [],\n",
       "   'source': ['print(\"Preparing final feature set...\")\\n',\n",
       "    'print(\"=\"*60)\\n',\n",
       "    '\\n',\n",
       "    '# Option 1: Use all features\\n',\n",
       "    'features_all = X.columns.tolist()\\n',\n",
       "    '\\n',\n",
       "    '# Option 2: Use selected features (union of correlation and univariate)\\n',\n",
       "    'features_selected = list(set(selected_features_corr) | set(selected_features_univariate))\\n',\n",
       "    '\\n',\n",
       "    '# Option 3: Use top features from univariate selection\\n',\n",
       "    'features_top = selected_features_univariate\\n',\n",
       "    '\\n',\n",
       "    'print(f\"\\\\nFeature set options:\")\\n',\n",
       "    'print(f\"  1. All features: {len(features_all)} features\")\\n',\n",
       "    'print(f\"  2. Selected features (union): {len(features_selected)} features\")\\n',\n",
       "    'print(f\"  3. Top univariate features: {len(features_top)} features\")\\n',\n",
       "    '\\n',\n",
       "    \"# We'll use Option 1 (all features) and let the model do feature selection\\n\",\n",
       "    'final_features = features_all\\n',\n",
       "    '\\n',\n",
       "    'print(f\"\\\\n✓ Using all features for modeling: {len(final_features)} features\")']},\n",
       "  {'cell_type': 'markdown',\n",
       "   'metadata': {},\n",
       "   'source': ['## 8. Train-Test Split']},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': None,\n",
       "   'metadata': {},\n",
       "   'outputs': [],\n",
       "   'source': ['print(\"Splitting data into train and test sets...\")\\n',\n",
       "    'print(\"=\"*60)\\n',\n",
       "    '\\n',\n",
       "    'X_final = df_encoded[final_features]\\n',\n",
       "    \"y_final = df_encoded['heart_attack']\\n\",\n",
       "    '\\n',\n",
       "    'X_train, X_test, y_train, y_test = preprocessor.prepare_data_for_modeling(\\n',\n",
       "    \"    df_encoded[final_features + ['heart_attack']], \\n\",\n",
       "    \"    target_column='heart_attack',\\n\",\n",
       "    '    test_size=0.2,\\n',\n",
       "    '    random_state=42\\n',\n",
       "    ')\\n',\n",
       "    '\\n',\n",
       "    'print(f\"\\\\nTrain set: {X_train.shape}\")\\n',\n",
       "    'print(f\"Test set: {X_test.shape}\")']},\n",
       "  {'cell_type': 'markdown',\n",
       "   'metadata': {},\n",
       "   'source': ['## 9. Feature Scaling']},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': None,\n",
       "   'metadata': {},\n",
       "   'outputs': [],\n",
       "   'source': ['print(\"Scaling features...\")\\n',\n",
       "    'print(\"=\"*60)\\n',\n",
       "    '\\n',\n",
       "    '# Scale features\\n',\n",
       "    'X_train_scaled, X_test_scaled = preprocessor.scale_features(X_train, X_test)\\n',\n",
       "    '\\n',\n",
       "    '# Convert back to DataFrame for easier handling\\n',\n",
       "    'X_train_scaled = pd.DataFrame(X_train_scaled, columns=X_train.columns, index=X_train.index)\\n',\n",
       "    'X_test_scaled = pd.DataFrame(X_test_scaled, columns=X_test.columns, index=X_test.index)\\n',\n",
       "    '\\n',\n",
       "    'print(\"\\\\n✓ Features scaled successfully!\")\\n',\n",
       "    'print(f\"\\\\nScaled train set: {X_train_scaled.shape}\")\\n',\n",
       "    'print(f\"Scaled test set: {X_test_scaled.shape}\")\\n',\n",
       "    '\\n',\n",
       "    '# Check scaling\\n',\n",
       "    'print(\"\\\\nScaled data statistics (sample features):\")\\n',\n",
       "    \"print(X_train_scaled[['age', 'cholesterol_level', 'blood_pressure_systolic']].describe())\"]},\n",
       "  {'cell_type': 'markdown',\n",
       "   'metadata': {},\n",
       "   'source': ['## 10. Save Processed Data']},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': None,\n",
       "   'metadata': {},\n",
       "   'outputs': [],\n",
       "   'source': ['print(\"Saving processed datasets...\")\\n',\n",
       "    'print(\"=\"*60)\\n',\n",
       "    '\\n',\n",
       "    '# Save engineered features dataset\\n',\n",
       "    \"df_encoded.to_csv('../data/heart_attack_data_engineered.csv', index=False)\\n\",\n",
       "    'print(\"✓ Engineered dataset saved: heart_attack_data_engineered.csv\")\\n',\n",
       "    '\\n',\n",
       "    '# Save train/test splits\\n',\n",
       "    \"X_train_scaled.to_csv('../data/X_train_scaled.csv', index=False)\\n\",\n",
       "    \"X_test_scaled.to_csv('../data/X_test_scaled.csv', index=False)\\n\",\n",
       "    \"y_train.to_csv('../data/y_train.csv', index=False)\\n\",\n",
       "    \"y_test.to_csv('../data/y_test.csv', index=False)\\n\",\n",
       "    '\\n',\n",
       "    'print(\"✓ Train/test splits saved:\")\\n',\n",
       "    'print(\"  - X_train_scaled.csv\")\\n',\n",
       "    'print(\"  - X_test_scaled.csv\")\\n',\n",
       "    'print(\"  - y_train.csv\")\\n',\n",
       "    'print(\"  - y_test.csv\")\\n',\n",
       "    '\\n',\n",
       "    '# Save feature names\\n',\n",
       "    \"pd.DataFrame({'feature': final_features}).to_csv('../data/feature_names.csv', index=False)\\n\",\n",
       "    'print(\"✓ Feature names saved: feature_names.csv\")\\n',\n",
       "    '\\n',\n",
       "    '# Save preprocessor objects\\n',\n",
       "    'import joblib\\n',\n",
       "    \"joblib.dump(preprocessor.scaler, '../models/scaler.pkl')\\n\",\n",
       "    \"joblib.dump(preprocessor.label_encoders, '../models/label_encoders.pkl')\\n\",\n",
       "    'print(\"\\\\n✓ Preprocessor objects saved:\")\\n',\n",
       "    'print(\"  - scaler.pkl\")\\n',\n",
       "    'print(\"  - label_encoders.pkl\")']},\n",
       "  {'cell_type': 'markdown',\n",
       "   'metadata': {},\n",
       "   'source': ['## 11. Feature Engineering Report']},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': None,\n",
       "   'metadata': {},\n",
       "   'outputs': [],\n",
       "   'source': ['print(\"\\\\n\" + \"=\"*60)\\n',\n",
       "    'print(\"FEATURE ENGINEERING SUMMARY REPORT\")\\n',\n",
       "    'print(\"=\"*60)\\n',\n",
       "    '\\n',\n",
       "    'print(f\"\\\\n1. DATASET TRANSFORMATION:\")\\n',\n",
       "    'print(f\"   Original features: {df.shape[1]}\")\\n',\n",
       "    'print(f\"   Engineered features: {df_encoded.shape[1]}\")\\n',\n",
       "    'print(f\"   New features created: {df_encoded.shape[1] - df.shape[1]}\")\\n',\n",
       "    '\\n',\n",
       "    'print(f\"\\\\n2. NEW FEATURES CREATED:\")\\n',\n",
       "    'new_features = set(df_encoded.columns) - set(df.columns)\\n',\n",
       "    'for i, feat in enumerate(sorted(new_features), 1):\\n',\n",
       "    '    print(f\"   {i:2d}. {feat}\")\\n',\n",
       "    '\\n',\n",
       "    'print(f\"\\\\n3. CATEGORICAL ENCODING:\")\\n',\n",
       "    'print(f\"   Encoded columns: {len(categorical_cols)}\")\\n',\n",
       "    'print(f\"   Encoding method: Label Encoding\")\\n',\n",
       "    '\\n',\n",
       "    'print(f\"\\\\n4. FEATURE SELECTION:\")\\n',\n",
       "    'print(f\"   Features by correlation (>{threshold}): {len(selected_features_corr)}\")\\n',\n",
       "    'print(f\"   Features by univariate test (top {k}): {len(selected_features_univariate)}\")\\n',\n",
       "    'print(f\"   Final features for modeling: {len(final_features)}\")\\n',\n",
       "    '\\n',\n",
       "    'print(f\"\\\\n5. DATA SPLIT:\")\\n',\n",
       "    'print(f\"   Training set: {X_train.shape[0]} samples ({X_train.shape[0]/len(df_encoded)*100:.1f}%)\")\\n',\n",
       "    'print(f\"   Test set: {X_test.shape[0]} samples ({X_test.shape[0]/len(df_encoded)*100:.1f}%)\")\\n',\n",
       "    '\\n',\n",
       "    'print(f\"\\\\n6. FEATURE SCALING:\")\\n',\n",
       "    'print(f\"   Scaling method: StandardScaler (z-score normalization)\")\\n',\n",
       "    'print(f\"   Scaled features: All numerical features\")\\n',\n",
       "    '\\n',\n",
       "    'print(f\"\\\\n7. TOP FEATURES (by correlation with target):\")\\n',\n",
       "    'top_5 = correlations.head(5)\\n',\n",
       "    'for i, (feat, corr) in enumerate(top_5.items(), 1):\\n',\n",
       "    '    print(f\"   {i}. {feat:30s}: {corr:+.4f}\")\\n',\n",
       "    '\\n',\n",
       "    'print(f\"\\\\n8. FILES SAVED:\")\\n',\n",
       "    'print(f\"   - heart_attack_data_engineered.csv (Full dataset with engineered features)\")\\n',\n",
       "    'print(f\"   - X_train_scaled.csv, X_test_scaled.csv (Scaled features)\")\\n',\n",
       "    'print(f\"   - y_train.csv, y_test.csv (Target variables)\")\\n',\n",
       "    'print(f\"   - feature_names.csv (List of features)\")\\n',\n",
       "    'print(f\"   - scaler.pkl, label_encoders.pkl (Preprocessing objects)\")\\n',\n",
       "    '\\n',\n",
       "    'print(\"\\\\n\" + \"=\"*60)\\n',\n",
       "    'print(\"✓ Feature Engineering Completed Successfully!\")\\n',\n",
       "    'print(\"=\"*60)']},\n",
       "  {'cell_type': 'markdown',\n",
       "   'metadata': {},\n",
       "   'source': ['## Summary\\n',\n",
       "    '\\n',\n",
       "    'Pada tahap Feature Engineering ini, kita telah:\\n',\n",
       "    '\\n',\n",
       "    '1. ✅ **Created New Features**:\\n',\n",
       "    '   - Age groups (categorical)\\n',\n",
       "    '   - Blood pressure categories\\n',\n",
       "    '   - Cholesterol categories\\n',\n",
       "    '   - BMI categories\\n',\n",
       "    '   - Composite risk score\\n',\n",
       "    '   - Interaction features (age × conditions, BP interactions, etc.)\\n',\n",
       "    '\\n',\n",
       "    '2. ✅ **Encoded Categorical Variables**:\\n',\n",
       "    '   - Label encoding untuk semua categorical features\\n',\n",
       "    '   - Preserved label encoders untuk future use\\n',\n",
       "    '\\n',\n",
       "    '3. ✅ **Feature Selection**:\\n',\n",
       "    '   - Correlation-based selection\\n',\n",
       "    '   - Univariate statistical tests\\n',\n",
       "    '   - Multicollinearity check\\n',\n",
       "    '\\n',\n",
       "    '4. ✅ **Data Preparation**:\\n',\n",
       "    '   - Train-test split (80-20)\\n',\n",
       "    '   - Feature scaling (StandardScaler)\\n',\n",
       "    '   - Stratified sampling untuk balanced classes\\n',\n",
       "    '\\n',\n",
       "    '5. ✅ **Saved Artifacts**:\\n',\n",
       "    '   - Processed datasets\\n',\n",
       "    '   - Preprocessing objects\\n',\n",
       "    '   - Feature names\\n',\n",
       "    '\\n',\n",
       "    '### Key Achievements:\\n',\n",
       "    '- Increased feature space dengan meaningful engineered features\\n',\n",
       "    '- Maintained interpretability of features\\n',\n",
       "    '- Prepared clean, scaled data ready for modeling\\n',\n",
       "    '- Created reusable preprocessing pipeline\\n',\n",
       "    '\\n',\n",
       "    '### Feature Quality:\\n',\n",
       "    '- All features properly encoded\\n',\n",
       "    '- No missing values\\n',\n",
       "    '- Scaled for consistent ranges\\n',\n",
       "    '- Low multicollinearity\\n',\n",
       "    '\\n',\n",
       "    '### Next Steps:\\n',\n",
       "    'Lanjut ke **Notebook 6: Predictive Modeling** untuk train machine learning models.\\n',\n",
       "    '\\n',\n",
       "    '---']}],\n",
       " 'metadata': {'kernelspec': {'display_name': 'Python 3',\n",
       "   'language': 'python',\n",
       "   'name': 'python3'},\n",
       "  'language_info': {'codemirror_mode': {'name': 'ipython', 'version': 3},\n",
       "   'file_extension': '.py',\n",
       "   'mimetype': 'text/x-python',\n",
       "   'name': 'python',\n",
       "   'nbconvert_exporter': 'python',\n",
       "   'pygments_lexer': 'ipython3',\n",
       "   'version': '3.9.0'}},\n",
       " 'nbformat': 4,\n",
       " 'nbformat_minor': 4}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{\n",
    " \"cells\": [\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Indonesia Heart Attack Prediction\\n\",\n",
    "    \"## Notebook 5: Feature Engineering\\n\",\n",
    "    \"\\n\",\n",
    "    \"---\\n\",\n",
    "    \"\\n\",\n",
    "    \"### Tahap 5 dari Data Science Life Cycle\\n\",\n",
    "    \"\\n\",\n",
    "    \"Pada tahap ini, kita akan:\\n\",\n",
    "    \"1. Create new features dari existing features\\n\",\n",
    "    \"2. Transform features untuk improve model performance\\n\",\n",
    "    \"3. Select important features\\n\",\n",
    "    \"4. Encode categorical variables\\n\",\n",
    "    \"5. Scale numerical features\\n\",\n",
    "    \"6. Prepare final dataset untuk modeling\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 1. Import Libraries dan Load Data\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": None,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Data manipulation\\n\",\n",
    "    \"import pandas as pd\\n\",\n",
    "    \"import numpy as np\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Visualization\\n\",\n",
    "    \"import matplotlib.pyplot as plt\\n\",\n",
    "    \"import seaborn as sns\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Feature engineering and selection\\n\",\n",
    "    \"from sklearn.preprocessing import LabelEncoder, StandardScaler\\n\",\n",
    "    \"from sklearn.feature_selection import SelectKBest, chi2, f_classif, mutual_info_classif\\n\",\n",
    "    \"\\n\",\n",
    "    \"# System utilities\\n\",\n",
    "    \"import sys\\n\",\n",
    "    \"sys.path.append('../src')\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Import custom modules\\n\",\n",
    "    \"from feature_engineering import FeatureEngineer, get_high_correlation_features, feature_summary\\n\",\n",
    "    \"from data_preprocessing import DataPreprocessor\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Settings\\n\",\n",
    "    \"pd.set_option('display.max_columns', None)\\n\",\n",
    "    \"plt.style.use('seaborn-v0_8-whitegrid')\\n\",\n",
    "    \"sns.set_palette('husl')\\n\",\n",
    "    \"\\n\",\n",
    "    \"import warnings\\n\",\n",
    "    \"warnings.filterwarnings('ignore')\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"Libraries imported successfully!\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": None,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Load cleaned data\\n\",\n",
    "    \"df = pd.read_csv('../data/heart_attack_data_cleaned.csv')\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"Original dataset shape: {df.shape}\\\")\\n\",\n",
    "    \"print(f\\\"Features: {df.shape[1]}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Initialize feature engineer\\n\",\n",
    "    \"fe = FeatureEngineer()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 2. Create New Features\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"### 2.1 Age-based Features\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": None,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"print(\\\"Creating age-based features...\\\")\\n\",\n",
    "    \"print(\\\"=\\\"*60)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Age groups\\n\",\n",
    "    \"df_engineered = fe.create_age_groups(df)\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"\\\\nAge groups created:\\\")\\n\",\n",
    "    \"print(df_engineered['age_group'].value_counts().sort_index())\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"### 2.2 Blood Pressure Categories\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": None,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"print(\\\"Creating blood pressure categories...\\\")\\n\",\n",
    "    \"print(\\\"=\\\"*60)\\n\",\n",
    "    \"\\n\",\n",
    "    \"df_engineered = fe.create_blood_pressure_category(df_engineered)\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"\\\\nBlood pressure categories:\\\")\\n\",\n",
    "    \"print(df_engineered['bp_category'].value_counts())\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"### 2.3 Cholesterol Categories\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": None,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"print(\\\"Creating cholesterol categories...\\\")\\n\",\n",
    "    \"print(\\\"=\\\"*60)\\n\",\n",
    "    \"\\n\",\n",
    "    \"df_engineered = fe.create_cholesterol_category(df_engineered)\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"\\\\nCholesterol categories:\\\")\\n\",\n",
    "    \"print(df_engineered['cholesterol_category'].value_counts())\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"### 2.4 BMI Category\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": None,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"print(\\\"Creating BMI categories...\\\")\\n\",\n",
    "    \"print(\\\"=\\\"*60)\\n\",\n",
    "    \"\\n\",\n",
    "    \"df_engineered = fe.create_bmi_category(df_engineered)\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"\\\\nBMI categories:\\\")\\n\",\n",
    "    \"print(df_engineered['bmi_category'].value_counts())\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"### 2.5 Risk Score (Composite Feature)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": None,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"print(\\\"Creating composite risk score...\\\")\\n\",\n",
    "    \"print(\\\"=\\\"*60)\\n\",\n",
    "    \"\\n\",\n",
    "    \"df_engineered = fe.create_risk_score(df_engineered)\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"\\\\nRisk score statistics:\\\")\\n\",\n",
    "    \"print(df_engineered['risk_score'].describe())\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Visualize risk score distribution\\n\",\n",
    "    \"fig, axes = plt.subplots(1, 2, figsize=(14, 5))\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Distribution\\n\",\n",
    "    \"df_engineered['risk_score'].hist(bins=15, ax=axes[0], color='steelblue', edgecolor='black')\\n\",\n",
    "    \"axes[0].set_title('Risk Score Distribution', fontsize=12, fontweight='bold')\\n\",\n",
    "    \"axes[0].set_xlabel('Risk Score')\\n\",\n",
    "    \"axes[0].set_ylabel('Frequency')\\n\",\n",
    "    \"axes[0].axvline(df_engineered['risk_score'].mean(), color='red', linestyle='--',\\n\",\n",
    "    \"               label=f'Mean: {df_engineered[\\\"risk_score\\\"].mean():.2f}')\\n\",\n",
    "    \"axes[0].legend()\\n\",\n",
    "    \"axes[0].grid(alpha=0.3)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Risk score vs heart attack\\n\",\n",
    "    \"df_engineered.boxplot(column='risk_score', by='heart_attack', ax=axes[1])\\n\",\n",
    "    \"axes[1].set_title('Risk Score by Heart Attack Status')\\n\",\n",
    "    \"axes[1].set_xlabel('Heart Attack')\\n\",\n",
    "    \"axes[1].set_ylabel('Risk Score')\\n\",\n",
    "    \"axes[1].set_xticklabels(['No', 'Yes'])\\n\",\n",
    "    \"plt.sca(axes[1])\\n\",\n",
    "    \"plt.xticks([1, 2], ['No', 'Yes'])\\n\",\n",
    "    \"\\n\",\n",
    "    \"plt.tight_layout()\\n\",\n",
    "    \"plt.show()\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Calculate mean risk score by heart attack status\\n\",\n",
    "    \"print(\\\"\\\\nMean risk score by heart attack status:\\\")\\n\",\n",
    "    \"print(df_engineered.groupby('heart_attack')['risk_score'].mean())\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"### 2.6 Interaction Features\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": None,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"print(\\\"Creating interaction features...\\\")\\n\",\n",
    "    \"print(\\\"=\\\"*60)\\n\",\n",
    "    \"\\n\",\n",
    "    \"df_engineered = fe.create_interaction_features(df_engineered)\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"\\\\nNew interaction features created:\\\")\\n\",\n",
    "    \"interaction_features = ['age_hypertension', 'age_diabetes', 'cholesterol_age', \\n\",\n",
    "    \"                       'bp_interaction', 'total_health_conditions']\\n\",\n",
    "    \"for feat in interaction_features:\\n\",\n",
    "    \"    if feat in df_engineered.columns:\\n\",\n",
    "    \"        print(f\\\"  - {feat}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 3. Feature Engineering Summary\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": None,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"print(\\\"Feature Engineering Summary:\\\")\\n\",\n",
    "    \"print(\\\"=\\\"*60)\\n\",\n",
    "    \"\\n\",\n",
    "    \"summary = feature_summary(df, df_engineered)\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"\\\\nOriginal features: {summary['original_features']}\\\")\\n\",\n",
    "    \"print(f\\\"Engineered features: {summary['engineered_features']}\\\")\\n\",\n",
    "    \"print(f\\\"New features created: {summary['new_features_count']}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"\\\\nList of new features:\\\")\\n\",\n",
    "    \"for i, feat in enumerate(summary['new_features_list'], 1):\\n\",\n",
    "    \"    print(f\\\"  {i}. {feat}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 4. Encode Categorical Variables\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": None,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"print(\\\"Encoding categorical variables...\\\")\\n\",\n",
    "    \"print(\\\"=\\\"*60)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Identify categorical columns\\n\",\n",
    "    \"categorical_cols = df_engineered.select_dtypes(include=['object']).columns.tolist()\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"\\\\nCategorical columns to encode: {len(categorical_cols)}\\\")\\n\",\n",
    "    \"for col in categorical_cols:\\n\",\n",
    "    \"    print(f\\\"  - {col}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Initialize preprocessor for encoding\\n\",\n",
    "    \"preprocessor = DataPreprocessor()\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Encode categorical variables\\n\",\n",
    "    \"df_encoded = preprocessor.encode_categorical(df_engineered, categorical_cols)\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"\\\\n✓ Categorical variables encoded successfully!\\\")\\n\",\n",
    "    \"print(f\\\"\\\\nDataset shape after encoding: {df_encoded.shape}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 5. Feature Correlation Analysis\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": None,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"print(\\\"Analyzing feature correlations with target...\\\")\\n\",\n",
    "    \"print(\\\"=\\\"*60)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Calculate correlation with heart_attack\\n\",\n",
    "    \"correlations = df_encoded.corr()['heart_attack'].drop('heart_attack').sort_values(ascending=False)\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"\\\\nTop 20 features correlated with Heart Attack:\\\")\\n\",\n",
    "    \"print(correlations.head(20))\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Visualize top correlations\\n\",\n",
    "    \"plt.figure(figsize=(12, 10))\\n\",\n",
    "    \"top_n = 20\\n\",\n",
    "    \"top_corr = correlations.head(top_n)\\n\",\n",
    "    \"colors = ['green' if x > 0 else 'red' for x in top_corr]\\n\",\n",
    "    \"\\n\",\n",
    "    \"plt.barh(range(len(top_corr)), top_corr.values, color=colors)\\n\",\n",
    "    \"plt.yticks(range(len(top_corr)), top_corr.index)\\n\",\n",
    "    \"plt.xlabel('Correlation Coefficient', fontsize=12)\\n\",\n",
    "    \"plt.title(f'Top {top_n} Features Correlated with Heart Attack', fontsize=14, fontweight='bold')\\n\",\n",
    "    \"plt.axvline(x=0, color='black', linestyle='--', linewidth=0.8)\\n\",\n",
    "    \"plt.grid(axis='x', alpha=0.3)\\n\",\n",
    "    \"plt.tight_layout()\\n\",\n",
    "    \"plt.show()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 6. Feature Selection\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"### 6.1 Correlation-based Feature Selection\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": None,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"print(\\\"Correlation-based Feature Selection:\\\")\\n\",\n",
    "    \"print(\\\"=\\\"*60)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Select features with correlation > threshold\\n\",\n",
    "    \"threshold = 0.05\\n\",\n",
    "    \"selected_features_corr = fe.select_features_correlation(df_encoded, 'heart_attack', threshold=threshold)\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"\\\\nFeatures selected (correlation > {threshold}): {len(selected_features_corr)}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"### 6.2 Univariate Feature Selection\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": None,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"print(\\\"Univariate Feature Selection:\\\")\\n\",\n",
    "    \"print(\\\"=\\\"*60)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Prepare X and y\\n\",\n",
    "    \"X = df_encoded.drop('heart_attack', axis=1)\\n\",\n",
    "    \"y = df_encoded['heart_attack']\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Select top K features using f_classif\\n\",\n",
    "    \"k = 20\\n\",\n",
    "    \"selected_features_univariate, selector = fe.select_features_univariate(X, y, k=k, score_func='f_classif')\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"\\\\nTop {k} features selected.\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"### 6.3 Check Multicollinearity\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": None,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"print(\\\"Checking for multicollinearity...\\\")\\n\",\n",
    "    \"print(\\\"=\\\"*60)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Find highly correlated features\\n\",\n",
    "    \"high_corr_pairs = get_high_correlation_features(df_encoded, threshold=0.8)\\n\",\n",
    "    \"\\n\",\n",
    "    \"if len(high_corr_pairs) > 0:\\n\",\n",
    "    \"    print(f\\\"\\\\nFound {len(high_corr_pairs)} pairs of highly correlated features (>0.8):\\\")\\n\",\n",
    "    \"    for pair in high_corr_pairs[:10]:  # Show first 10\\n\",\n",
    "    \"        print(f\\\"  {pair[0]} <-> {pair[1]}: {pair[2]:.3f}\\\")\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    print(\\\"\\\\n⚠️  Consider removing one feature from each highly correlated pair.\\\")\\n\",\n",
    "    \"else:\\n\",\n",
    "    \"    print(\\\"\\\\n✓ No high multicollinearity detected.\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 7. Prepare Final Feature Set\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": None,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"print(\\\"Preparing final feature set...\\\")\\n\",\n",
    "    \"print(\\\"=\\\"*60)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Option 1: Use all features\\n\",\n",
    "    \"features_all = X.columns.tolist()\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Option 2: Use selected features (union of correlation and univariate)\\n\",\n",
    "    \"features_selected = list(set(selected_features_corr) | set(selected_features_univariate))\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Option 3: Use top features from univariate selection\\n\",\n",
    "    \"features_top = selected_features_univariate\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"\\\\nFeature set options:\\\")\\n\",\n",
    "    \"print(f\\\"  1. All features: {len(features_all)} features\\\")\\n\",\n",
    "    \"print(f\\\"  2. Selected features (union): {len(features_selected)} features\\\")\\n\",\n",
    "    \"print(f\\\"  3. Top univariate features: {len(features_top)} features\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# We'll use Option 1 (all features) and let the model do feature selection\\n\",\n",
    "    \"final_features = features_all\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"\\\\n✓ Using all features for modeling: {len(final_features)} features\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 8. Train-Test Split\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": None,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"print(\\\"Splitting data into train and test sets...\\\")\\n\",\n",
    "    \"print(\\\"=\\\"*60)\\n\",\n",
    "    \"\\n\",\n",
    "    \"X_final = df_encoded[final_features]\\n\",\n",
    "    \"y_final = df_encoded['heart_attack']\\n\",\n",
    "    \"\\n\",\n",
    "    \"X_train, X_test, y_train, y_test = preprocessor.prepare_data_for_modeling(\\n\",\n",
    "    \"    df_encoded[final_features + ['heart_attack']], \\n\",\n",
    "    \"    target_column='heart_attack',\\n\",\n",
    "    \"    test_size=0.2,\\n\",\n",
    "    \"    random_state=42\\n\",\n",
    "    \")\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"\\\\nTrain set: {X_train.shape}\\\")\\n\",\n",
    "    \"print(f\\\"Test set: {X_test.shape}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 9. Feature Scaling\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": None,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"print(\\\"Scaling features...\\\")\\n\",\n",
    "    \"print(\\\"=\\\"*60)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Scale features\\n\",\n",
    "    \"X_train_scaled, X_test_scaled = preprocessor.scale_features(X_train, X_test)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Convert back to DataFrame for easier handling\\n\",\n",
    "    \"X_train_scaled = pd.DataFrame(X_train_scaled, columns=X_train.columns, index=X_train.index)\\n\",\n",
    "    \"X_test_scaled = pd.DataFrame(X_test_scaled, columns=X_test.columns, index=X_test.index)\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"\\\\n✓ Features scaled successfully!\\\")\\n\",\n",
    "    \"print(f\\\"\\\\nScaled train set: {X_train_scaled.shape}\\\")\\n\",\n",
    "    \"print(f\\\"Scaled test set: {X_test_scaled.shape}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Check scaling\\n\",\n",
    "    \"print(\\\"\\\\nScaled data statistics (sample features):\\\")\\n\",\n",
    "    \"print(X_train_scaled[['age', 'cholesterol_level', 'blood_pressure_systolic']].describe())\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 10. Save Processed Data\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": None,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"print(\\\"Saving processed datasets...\\\")\\n\",\n",
    "    \"print(\\\"=\\\"*60)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Save engineered features dataset\\n\",\n",
    "    \"df_encoded.to_csv('../data/heart_attack_data_engineered.csv', index=False)\\n\",\n",
    "    \"print(\\\"✓ Engineered dataset saved: heart_attack_data_engineered.csv\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Save train/test splits\\n\",\n",
    "    \"X_train_scaled.to_csv('../data/X_train_scaled.csv', index=False)\\n\",\n",
    "    \"X_test_scaled.to_csv('../data/X_test_scaled.csv', index=False)\\n\",\n",
    "    \"y_train.to_csv('../data/y_train.csv', index=False)\\n\",\n",
    "    \"y_test.to_csv('../data/y_test.csv', index=False)\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"✓ Train/test splits saved:\\\")\\n\",\n",
    "    \"print(\\\"  - X_train_scaled.csv\\\")\\n\",\n",
    "    \"print(\\\"  - X_test_scaled.csv\\\")\\n\",\n",
    "    \"print(\\\"  - y_train.csv\\\")\\n\",\n",
    "    \"print(\\\"  - y_test.csv\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Save feature names\\n\",\n",
    "    \"pd.DataFrame({'feature': final_features}).to_csv('../data/feature_names.csv', index=False)\\n\",\n",
    "    \"print(\\\"✓ Feature names saved: feature_names.csv\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Save preprocessor objects\\n\",\n",
    "    \"import joblib\\n\",\n",
    "    \"joblib.dump(preprocessor.scaler, '../models/scaler.pkl')\\n\",\n",
    "    \"joblib.dump(preprocessor.label_encoders, '../models/label_encoders.pkl')\\n\",\n",
    "    \"print(\\\"\\\\n✓ Preprocessor objects saved:\\\")\\n\",\n",
    "    \"print(\\\"  - scaler.pkl\\\")\\n\",\n",
    "    \"print(\\\"  - label_encoders.pkl\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 11. Feature Engineering Report\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": None,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"print(\\\"\\\\n\\\" + \\\"=\\\"*60)\\n\",\n",
    "    \"print(\\\"FEATURE ENGINEERING SUMMARY REPORT\\\")\\n\",\n",
    "    \"print(\\\"=\\\"*60)\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"\\\\n1. DATASET TRANSFORMATION:\\\")\\n\",\n",
    "    \"print(f\\\"   Original features: {df.shape[1]}\\\")\\n\",\n",
    "    \"print(f\\\"   Engineered features: {df_encoded.shape[1]}\\\")\\n\",\n",
    "    \"print(f\\\"   New features created: {df_encoded.shape[1] - df.shape[1]}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"\\\\n2. NEW FEATURES CREATED:\\\")\\n\",\n",
    "    \"new_features = set(df_encoded.columns) - set(df.columns)\\n\",\n",
    "    \"for i, feat in enumerate(sorted(new_features), 1):\\n\",\n",
    "    \"    print(f\\\"   {i:2d}. {feat}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"\\\\n3. CATEGORICAL ENCODING:\\\")\\n\",\n",
    "    \"print(f\\\"   Encoded columns: {len(categorical_cols)}\\\")\\n\",\n",
    "    \"print(f\\\"   Encoding method: Label Encoding\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"\\\\n4. FEATURE SELECTION:\\\")\\n\",\n",
    "    \"print(f\\\"   Features by correlation (>{threshold}): {len(selected_features_corr)}\\\")\\n\",\n",
    "    \"print(f\\\"   Features by univariate test (top {k}): {len(selected_features_univariate)}\\\")\\n\",\n",
    "    \"print(f\\\"   Final features for modeling: {len(final_features)}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"\\\\n5. DATA SPLIT:\\\")\\n\",\n",
    "    \"print(f\\\"   Training set: {X_train.shape[0]} samples ({X_train.shape[0]/len(df_encoded)*100:.1f}%)\\\")\\n\",\n",
    "    \"print(f\\\"   Test set: {X_test.shape[0]} samples ({X_test.shape[0]/len(df_encoded)*100:.1f}%)\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"\\\\n6. FEATURE SCALING:\\\")\\n\",\n",
    "    \"print(f\\\"   Scaling method: StandardScaler (z-score normalization)\\\")\\n\",\n",
    "    \"print(f\\\"   Scaled features: All numerical features\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"\\\\n7. TOP FEATURES (by correlation with target):\\\")\\n\",\n",
    "    \"top_5 = correlations.head(5)\\n\",\n",
    "    \"for i, (feat, corr) in enumerate(top_5.items(), 1):\\n\",\n",
    "    \"    print(f\\\"   {i}. {feat:30s}: {corr:+.4f}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"\\\\n8. FILES SAVED:\\\")\\n\",\n",
    "    \"print(f\\\"   - heart_attack_data_engineered.csv (Full dataset with engineered features)\\\")\\n\",\n",
    "    \"print(f\\\"   - X_train_scaled.csv, X_test_scaled.csv (Scaled features)\\\")\\n\",\n",
    "    \"print(f\\\"   - y_train.csv, y_test.csv (Target variables)\\\")\\n\",\n",
    "    \"print(f\\\"   - feature_names.csv (List of features)\\\")\\n\",\n",
    "    \"print(f\\\"   - scaler.pkl, label_encoders.pkl (Preprocessing objects)\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"\\\\n\\\" + \\\"=\\\"*60)\\n\",\n",
    "    \"print(\\\"✓ Feature Engineering Completed Successfully!\\\")\\n\",\n",
    "    \"print(\\\"=\\\"*60)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## Summary\\n\",\n",
    "    \"\\n\",\n",
    "    \"Pada tahap Feature Engineering ini, kita telah:\\n\",\n",
    "    \"\\n\",\n",
    "    \"1. ✅ **Created New Features**:\\n\",\n",
    "    \"   - Age groups (categorical)\\n\",\n",
    "    \"   - Blood pressure categories\\n\",\n",
    "    \"   - Cholesterol categories\\n\",\n",
    "    \"   - BMI categories\\n\",\n",
    "    \"   - Composite risk score\\n\",\n",
    "    \"   - Interaction features (age × conditions, BP interactions, etc.)\\n\",\n",
    "    \"\\n\",\n",
    "    \"2. ✅ **Encoded Categorical Variables**:\\n\",\n",
    "    \"   - Label encoding untuk semua categorical features\\n\",\n",
    "    \"   - Preserved label encoders untuk future use\\n\",\n",
    "    \"\\n\",\n",
    "    \"3. ✅ **Feature Selection**:\\n\",\n",
    "    \"   - Correlation-based selection\\n\",\n",
    "    \"   - Univariate statistical tests\\n\",\n",
    "    \"   - Multicollinearity check\\n\",\n",
    "    \"\\n\",\n",
    "    \"4. ✅ **Data Preparation**:\\n\",\n",
    "    \"   - Train-test split (80-20)\\n\",\n",
    "    \"   - Feature scaling (StandardScaler)\\n\",\n",
    "    \"   - Stratified sampling untuk balanced classes\\n\",\n",
    "    \"\\n\",\n",
    "    \"5. ✅ **Saved Artifacts**:\\n\",\n",
    "    \"   - Processed datasets\\n\",\n",
    "    \"   - Preprocessing objects\\n\",\n",
    "    \"   - Feature names\\n\",\n",
    "    \"\\n\",\n",
    "    \"### Key Achievements:\\n\",\n",
    "    \"- Increased feature space dengan meaningful engineered features\\n\",\n",
    "    \"- Maintained interpretability of features\\n\",\n",
    "    \"- Prepared clean, scaled data ready for modeling\\n\",\n",
    "    \"- Created reusable preprocessing pipeline\\n\",\n",
    "    \"\\n\",\n",
    "    \"### Feature Quality:\\n\",\n",
    "    \"- All features properly encoded\\n\",\n",
    "    \"- No missing values\\n\",\n",
    "    \"- Scaled for consistent ranges\\n\",\n",
    "    \"- Low multicollinearity\\n\",\n",
    "    \"\\n\",\n",
    "    \"### Next Steps:\\n\",\n",
    "    \"Lanjut ke **Notebook 6: Predictive Modeling** untuk train machine learning models.\\n\",\n",
    "    \"\\n\",\n",
    "    \"---\"\n",
    "   ]\n",
    "  }\n",
    " ],\n",
    " \"metadata\": {\n",
    "  \"kernelspec\": {\n",
    "   \"display_name\": \"Python 3\",\n",
    "   \"language\": \"python\",\n",
    "   \"name\": \"python3\"\n",
    "  },\n",
    "  \"language_info\": {\n",
    "   \"codemirror_mode\": {\n",
    "    \"name\": \"ipython\",\n",
    "    \"version\": 3\n",
    "   },\n",
    "   \"file_extension\": \".py\",\n",
    "   \"mimetype\": \"text/x-python\",\n",
    "   \"name\": \"python\",\n",
    "   \"nbconvert_exporter\": \"python\",\n",
    "   \"pygments_lexer\": \"ipython3\",\n",
    "   \"version\": \"3.9.0\"\n",
    "  }\n",
    " },\n",
    " \"nbformat\": 4,\n",
    " \"nbformat_minor\": 4\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63210637-5e3d-44bb-a531-939af5f442f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================================\n",
      "05. FEATURE ENGINEERING\n",
      "==============================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>region</th>\n",
       "      <th>income_level</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>cholesterol_level</th>\n",
       "      <th>obesity</th>\n",
       "      <th>waist_circumference</th>\n",
       "      <th>family_history</th>\n",
       "      <th>...</th>\n",
       "      <th>blood_pressure_diastolic</th>\n",
       "      <th>fasting_blood_sugar</th>\n",
       "      <th>cholesterol_hdl</th>\n",
       "      <th>cholesterol_ldl</th>\n",
       "      <th>triglycerides</th>\n",
       "      <th>EKG_results</th>\n",
       "      <th>previous_heart_disease</th>\n",
       "      <th>medication_usage</th>\n",
       "      <th>participated_in_free_screening</th>\n",
       "      <th>heart_attack</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>Male</td>\n",
       "      <td>Rural</td>\n",
       "      <td>Middle</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>211</td>\n",
       "      <td>0</td>\n",
       "      <td>83</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>62</td>\n",
       "      <td>173</td>\n",
       "      <td>48</td>\n",
       "      <td>121</td>\n",
       "      <td>101</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53</td>\n",
       "      <td>Female</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Low</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>208</td>\n",
       "      <td>0</td>\n",
       "      <td>106</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>76</td>\n",
       "      <td>70</td>\n",
       "      <td>58</td>\n",
       "      <td>83</td>\n",
       "      <td>138</td>\n",
       "      <td>Normal</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>62</td>\n",
       "      <td>Female</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Low</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>231</td>\n",
       "      <td>1</td>\n",
       "      <td>112</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>74</td>\n",
       "      <td>118</td>\n",
       "      <td>69</td>\n",
       "      <td>130</td>\n",
       "      <td>171</td>\n",
       "      <td>Abnormal</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>73</td>\n",
       "      <td>Male</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Low</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>202</td>\n",
       "      <td>0</td>\n",
       "      <td>82</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>65</td>\n",
       "      <td>98</td>\n",
       "      <td>52</td>\n",
       "      <td>85</td>\n",
       "      <td>146</td>\n",
       "      <td>Normal</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>52</td>\n",
       "      <td>Male</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Middle</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>232</td>\n",
       "      <td>0</td>\n",
       "      <td>89</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>75</td>\n",
       "      <td>104</td>\n",
       "      <td>59</td>\n",
       "      <td>127</td>\n",
       "      <td>139</td>\n",
       "      <td>Normal</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  gender region income_level  hypertension  diabetes  cholesterol_level  \\\n",
       "0   60    Male  Rural       Middle             0         1                211   \n",
       "1   53  Female  Urban          Low             0         0                208   \n",
       "2   62  Female  Urban          Low             0         0                231   \n",
       "3   73    Male  Urban          Low             1         0                202   \n",
       "4   52    Male  Urban       Middle             1         0                232   \n",
       "\n",
       "   obesity  waist_circumference  family_history  ... blood_pressure_diastolic  \\\n",
       "0        0                   83               0  ...                       62   \n",
       "1        0                  106               1  ...                       76   \n",
       "2        1                  112               1  ...                       74   \n",
       "3        0                   82               1  ...                       65   \n",
       "4        0                   89               0  ...                       75   \n",
       "\n",
       "  fasting_blood_sugar cholesterol_hdl cholesterol_ldl triglycerides  \\\n",
       "0                 173              48             121           101   \n",
       "1                  70              58              83           138   \n",
       "2                 118              69             130           171   \n",
       "3                  98              52              85           146   \n",
       "4                 104              59             127           139   \n",
       "\n",
       "  EKG_results  previous_heart_disease  medication_usage  \\\n",
       "0      Normal                       0                 0   \n",
       "1      Normal                       1                 0   \n",
       "2    Abnormal                       0                 1   \n",
       "3      Normal                       0                 1   \n",
       "4      Normal                       1                 0   \n",
       "\n",
       "   participated_in_free_screening  heart_attack  \n",
       "0                               0             0  \n",
       "1                               1             0  \n",
       "2                               0             1  \n",
       "3                               1             0  \n",
       "4                               1             1  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "print(\"==============================================\")\n",
    "print(\"05. FEATURE ENGINEERING\")\n",
    "print(\"==============================================\")\n",
    "\n",
    "df = pd.read_csv('../data/heart_attack_data.csv')\n",
    "\n",
    "# Menampilkan 5 baris awal data\n",
    "df.head()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
