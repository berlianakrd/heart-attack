{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57c833a0",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cells': [{'cell_type': 'markdown',\n",
       "   'metadata': {},\n",
       "   'source': ['# Indonesia Heart Attack Prediction\\n',\n",
       "    '## Notebook 5: Feature Engineering\\n',\n",
       "    '\\n',\n",
       "    '---\\n',\n",
       "    '\\n',\n",
       "    '### Tahap 5 dari Data Science Life Cycle\\n',\n",
       "    '\\n',\n",
       "    'Pada tahap ini, kita akan:\\n',\n",
       "    '1. Create new features dari existing features\\n',\n",
       "    '2. Transform features untuk improve model performance\\n',\n",
       "    '3. Select important features\\n',\n",
       "    '4. Encode categorical variables\\n',\n",
       "    '5. Scale numerical features\\n',\n",
       "    '6. Prepare final dataset untuk modeling']},\n",
       "  {'cell_type': 'markdown',\n",
       "   'metadata': {},\n",
       "   'source': ['## 1. Import Libraries dan Load Data']},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': None,\n",
       "   'metadata': {},\n",
       "   'outputs': [],\n",
       "   'source': ['# Data manipulation\\n',\n",
       "    'import pandas as pd\\n',\n",
       "    'import numpy as np\\n',\n",
       "    '\\n',\n",
       "    '# Visualization\\n',\n",
       "    'import matplotlib.pyplot as plt\\n',\n",
       "    'import seaborn as sns\\n',\n",
       "    '\\n',\n",
       "    '# Feature engineering and selection\\n',\n",
       "    'from sklearn.preprocessing import LabelEncoder, StandardScaler\\n',\n",
       "    'from sklearn.feature_selection import SelectKBest, chi2, f_classif, mutual_info_classif\\n',\n",
       "    '\\n',\n",
       "    '# System utilities\\n',\n",
       "    'import sys\\n',\n",
       "    \"sys.path.append('../src')\\n\",\n",
       "    '\\n',\n",
       "    '# Import custom modules\\n',\n",
       "    'from feature_engineering import FeatureEngineer, get_high_correlation_features, feature_summary\\n',\n",
       "    'from data_preprocessing import DataPreprocessor\\n',\n",
       "    '\\n',\n",
       "    '# Settings\\n',\n",
       "    \"pd.set_option('display.max_columns', None)\\n\",\n",
       "    \"plt.style.use('seaborn-v0_8-whitegrid')\\n\",\n",
       "    \"sns.set_palette('husl')\\n\",\n",
       "    '\\n',\n",
       "    'import warnings\\n',\n",
       "    \"warnings.filterwarnings('ignore')\\n\",\n",
       "    '\\n',\n",
       "    'print(\"Libraries imported successfully!\")']},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': None,\n",
       "   'metadata': {},\n",
       "   'outputs': [],\n",
       "   'source': ['# Load cleaned data\\n',\n",
       "    \"df = pd.read_csv('../data/heart_attack_data_cleaned.csv')\\n\",\n",
       "    '\\n',\n",
       "    'print(f\"Original dataset shape: {df.shape}\")\\n',\n",
       "    'print(f\"Features: {df.shape[1]}\")\\n',\n",
       "    '\\n',\n",
       "    '# Initialize feature engineer\\n',\n",
       "    'fe = FeatureEngineer()']},\n",
       "  {'cell_type': 'markdown',\n",
       "   'metadata': {},\n",
       "   'source': ['## 2. Create New Features']},\n",
       "  {'cell_type': 'markdown',\n",
       "   'metadata': {},\n",
       "   'source': ['### 2.1 Age-based Features']},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': None,\n",
       "   'metadata': {},\n",
       "   'outputs': [],\n",
       "   'source': ['print(\"Creating age-based features...\")\\n',\n",
       "    'print(\"=\"*60)\\n',\n",
       "    '\\n',\n",
       "    '# Age groups\\n',\n",
       "    'df_engineered = fe.create_age_groups(df)\\n',\n",
       "    '\\n',\n",
       "    'print(\"\\\\nAge groups created:\")\\n',\n",
       "    \"print(df_engineered['age_group'].value_counts().sort_index())\"]},\n",
       "  {'cell_type': 'markdown',\n",
       "   'metadata': {},\n",
       "   'source': ['### 2.2 Blood Pressure Categories']},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': None,\n",
       "   'metadata': {},\n",
       "   'outputs': [],\n",
       "   'source': ['print(\"Creating blood pressure categories...\")\\n',\n",
       "    'print(\"=\"*60)\\n',\n",
       "    '\\n',\n",
       "    'df_engineered = fe.create_blood_pressure_category(df_engineered)\\n',\n",
       "    '\\n',\n",
       "    'print(\"\\\\nBlood pressure categories:\")\\n',\n",
       "    \"print(df_engineered['bp_category'].value_counts())\"]},\n",
       "  {'cell_type': 'markdown',\n",
       "   'metadata': {},\n",
       "   'source': ['### 2.3 Cholesterol Categories']},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': None,\n",
       "   'metadata': {},\n",
       "   'outputs': [],\n",
       "   'source': ['print(\"Creating cholesterol categories...\")\\n',\n",
       "    'print(\"=\"*60)\\n',\n",
       "    '\\n',\n",
       "    'df_engineered = fe.create_cholesterol_category(df_engineered)\\n',\n",
       "    '\\n',\n",
       "    'print(\"\\\\nCholesterol categories:\")\\n',\n",
       "    \"print(df_engineered['cholesterol_category'].value_counts())\"]},\n",
       "  {'cell_type': 'markdown',\n",
       "   'metadata': {},\n",
       "   'source': ['### 2.4 BMI Category']},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': None,\n",
       "   'metadata': {},\n",
       "   'outputs': [],\n",
       "   'source': ['print(\"Creating BMI categories...\")\\n',\n",
       "    'print(\"=\"*60)\\n',\n",
       "    '\\n',\n",
       "    'df_engineered = fe.create_bmi_category(df_engineered)\\n',\n",
       "    '\\n',\n",
       "    'print(\"\\\\nBMI categories:\")\\n',\n",
       "    \"print(df_engineered['bmi_category'].value_counts())\"]},\n",
       "  {'cell_type': 'markdown',\n",
       "   'metadata': {},\n",
       "   'source': ['### 2.5 Risk Score (Composite Feature)']},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': None,\n",
       "   'metadata': {},\n",
       "   'outputs': [],\n",
       "   'source': ['print(\"Creating composite risk score...\")\\n',\n",
       "    'print(\"=\"*60)\\n',\n",
       "    '\\n',\n",
       "    'df_engineered = fe.create_risk_score(df_engineered)\\n',\n",
       "    '\\n',\n",
       "    'print(\"\\\\nRisk score statistics:\")\\n',\n",
       "    \"print(df_engineered['risk_score'].describe())\\n\",\n",
       "    '\\n',\n",
       "    '# Visualize risk score distribution\\n',\n",
       "    'fig, axes = plt.subplots(1, 2, figsize=(14, 5))\\n',\n",
       "    '\\n',\n",
       "    '# Distribution\\n',\n",
       "    \"df_engineered['risk_score'].hist(bins=15, ax=axes[0], color='steelblue', edgecolor='black')\\n\",\n",
       "    \"axes[0].set_title('Risk Score Distribution', fontsize=12, fontweight='bold')\\n\",\n",
       "    \"axes[0].set_xlabel('Risk Score')\\n\",\n",
       "    \"axes[0].set_ylabel('Frequency')\\n\",\n",
       "    \"axes[0].axvline(df_engineered['risk_score'].mean(), color='red', linestyle='--',\\n\",\n",
       "    '               label=f\\'Mean: {df_engineered[\"risk_score\"].mean():.2f}\\')\\n',\n",
       "    'axes[0].legend()\\n',\n",
       "    'axes[0].grid(alpha=0.3)\\n',\n",
       "    '\\n',\n",
       "    '# Risk score vs heart attack\\n',\n",
       "    \"df_engineered.boxplot(column='risk_score', by='heart_attack', ax=axes[1])\\n\",\n",
       "    \"axes[1].set_title('Risk Score by Heart Attack Status')\\n\",\n",
       "    \"axes[1].set_xlabel('Heart Attack')\\n\",\n",
       "    \"axes[1].set_ylabel('Risk Score')\\n\",\n",
       "    \"axes[1].set_xticklabels(['No', 'Yes'])\\n\",\n",
       "    'plt.sca(axes[1])\\n',\n",
       "    \"plt.xticks([1, 2], ['No', 'Yes'])\\n\",\n",
       "    '\\n',\n",
       "    'plt.tight_layout()\\n',\n",
       "    'plt.show()\\n',\n",
       "    '\\n',\n",
       "    '# Calculate mean risk score by heart attack status\\n',\n",
       "    'print(\"\\\\nMean risk score by heart attack status:\")\\n',\n",
       "    \"print(df_engineered.groupby('heart_attack')['risk_score'].mean())\"]},\n",
       "  {'cell_type': 'markdown',\n",
       "   'metadata': {},\n",
       "   'source': ['### 2.6 Interaction Features']},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': None,\n",
       "   'metadata': {},\n",
       "   'outputs': [],\n",
       "   'source': ['print(\"Creating interaction features...\")\\n',\n",
       "    'print(\"=\"*60)\\n',\n",
       "    '\\n',\n",
       "    'df_engineered = fe.create_interaction_features(df_engineered)\\n',\n",
       "    '\\n',\n",
       "    'print(\"\\\\nNew interaction features created:\")\\n',\n",
       "    \"interaction_features = ['age_hypertension', 'age_diabetes', 'cholesterol_age', \\n\",\n",
       "    \"                       'bp_interaction', 'total_health_conditions']\\n\",\n",
       "    'for feat in interaction_features:\\n',\n",
       "    '    if feat in df_engineered.columns:\\n',\n",
       "    '        print(f\"  - {feat}\")']},\n",
       "  {'cell_type': 'markdown',\n",
       "   'metadata': {},\n",
       "   'source': ['## 3. Feature Engineering Summary']},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': None,\n",
       "   'metadata': {},\n",
       "   'outputs': [],\n",
       "   'source': ['print(\"Feature Engineering Summary:\")\\n',\n",
       "    'print(\"=\"*60)\\n',\n",
       "    '\\n',\n",
       "    'summary = feature_summary(df, df_engineered)\\n',\n",
       "    '\\n',\n",
       "    'print(f\"\\\\nOriginal features: {summary[\\'original_features\\']}\")\\n',\n",
       "    'print(f\"Engineered features: {summary[\\'engineered_features\\']}\")\\n',\n",
       "    'print(f\"New features created: {summary[\\'new_features_count\\']}\")\\n',\n",
       "    '\\n',\n",
       "    'print(f\"\\\\nList of new features:\")\\n',\n",
       "    \"for i, feat in enumerate(summary['new_features_list'], 1):\\n\",\n",
       "    '    print(f\"  {i}. {feat}\")']},\n",
       "  {'cell_type': 'markdown',\n",
       "   'metadata': {},\n",
       "   'source': ['## 4. Encode Categorical Variables']},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': None,\n",
       "   'metadata': {},\n",
       "   'outputs': [],\n",
       "   'source': ['print(\"Encoding categorical variables...\")\\n',\n",
       "    'print(\"=\"*60)\\n',\n",
       "    '\\n',\n",
       "    '# Identify categorical columns\\n',\n",
       "    \"categorical_cols = df_engineered.select_dtypes(include=['object']).columns.tolist()\\n\",\n",
       "    '\\n',\n",
       "    'print(f\"\\\\nCategorical columns to encode: {len(categorical_cols)}\")\\n',\n",
       "    'for col in categorical_cols:\\n',\n",
       "    '    print(f\"  - {col}\")\\n',\n",
       "    '\\n',\n",
       "    '# Initialize preprocessor for encoding\\n',\n",
       "    'preprocessor = DataPreprocessor()\\n',\n",
       "    '\\n',\n",
       "    '# Encode categorical variables\\n',\n",
       "    'df_encoded = preprocessor.encode_categorical(df_engineered, categorical_cols)\\n',\n",
       "    '\\n',\n",
       "    'print(\"\\\\n✓ Categorical variables encoded successfully!\")\\n',\n",
       "    'print(f\"\\\\nDataset shape after encoding: {df_encoded.shape}\")']},\n",
       "  {'cell_type': 'markdown',\n",
       "   'metadata': {},\n",
       "   'source': ['## 5. Feature Correlation Analysis']},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': None,\n",
       "   'metadata': {},\n",
       "   'outputs': [],\n",
       "   'source': ['print(\"Analyzing feature correlations with target...\")\\n',\n",
       "    'print(\"=\"*60)\\n',\n",
       "    '\\n',\n",
       "    '# Calculate correlation with heart_attack\\n',\n",
       "    \"correlations = df_encoded.corr()['heart_attack'].drop('heart_attack').sort_values(ascending=False)\\n\",\n",
       "    '\\n',\n",
       "    'print(\"\\\\nTop 20 features correlated with Heart Attack:\")\\n',\n",
       "    'print(correlations.head(20))\\n',\n",
       "    '\\n',\n",
       "    '# Visualize top correlations\\n',\n",
       "    'plt.figure(figsize=(12, 10))\\n',\n",
       "    'top_n = 20\\n',\n",
       "    'top_corr = correlations.head(top_n)\\n',\n",
       "    \"colors = ['green' if x > 0 else 'red' for x in top_corr]\\n\",\n",
       "    '\\n',\n",
       "    'plt.barh(range(len(top_corr)), top_corr.values, color=colors)\\n',\n",
       "    'plt.yticks(range(len(top_corr)), top_corr.index)\\n',\n",
       "    \"plt.xlabel('Correlation Coefficient', fontsize=12)\\n\",\n",
       "    \"plt.title(f'Top {top_n} Features Correlated with Heart Attack', fontsize=14, fontweight='bold')\\n\",\n",
       "    \"plt.axvline(x=0, color='black', linestyle='--', linewidth=0.8)\\n\",\n",
       "    \"plt.grid(axis='x', alpha=0.3)\\n\",\n",
       "    'plt.tight_layout()\\n',\n",
       "    'plt.show()']},\n",
       "  {'cell_type': 'markdown',\n",
       "   'metadata': {},\n",
       "   'source': ['## 6. Feature Selection']},\n",
       "  {'cell_type': 'markdown',\n",
       "   'metadata': {},\n",
       "   'source': ['### 6.1 Correlation-based Feature Selection']},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': None,\n",
       "   'metadata': {},\n",
       "   'outputs': [],\n",
       "   'source': ['print(\"Correlation-based Feature Selection:\")\\n',\n",
       "    'print(\"=\"*60)\\n',\n",
       "    '\\n',\n",
       "    '# Select features with correlation > threshold\\n',\n",
       "    'threshold = 0.05\\n',\n",
       "    \"selected_features_corr = fe.select_features_correlation(df_encoded, 'heart_attack', threshold=threshold)\\n\",\n",
       "    '\\n',\n",
       "    'print(f\"\\\\nFeatures selected (correlation > {threshold}): {len(selected_features_corr)}\")']},\n",
       "  {'cell_type': 'markdown',\n",
       "   'metadata': {},\n",
       "   'source': ['### 6.2 Univariate Feature Selection']},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': None,\n",
       "   'metadata': {},\n",
       "   'outputs': [],\n",
       "   'source': ['print(\"Univariate Feature Selection:\")\\n',\n",
       "    'print(\"=\"*60)\\n',\n",
       "    '\\n',\n",
       "    '# Prepare X and y\\n',\n",
       "    \"X = df_encoded.drop('heart_attack', axis=1)\\n\",\n",
       "    \"y = df_encoded['heart_attack']\\n\",\n",
       "    '\\n',\n",
       "    '# Select top K features using f_classif\\n',\n",
       "    'k = 20\\n',\n",
       "    \"selected_features_univariate, selector = fe.select_features_univariate(X, y, k=k, score_func='f_classif')\\n\",\n",
       "    '\\n',\n",
       "    'print(f\"\\\\nTop {k} features selected.\")']},\n",
       "  {'cell_type': 'markdown',\n",
       "   'metadata': {},\n",
       "   'source': ['### 6.3 Check Multicollinearity']},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': None,\n",
       "   'metadata': {},\n",
       "   'outputs': [],\n",
       "   'source': ['print(\"Checking for multicollinearity...\")\\n',\n",
       "    'print(\"=\"*60)\\n',\n",
       "    '\\n',\n",
       "    '# Find highly correlated features\\n',\n",
       "    'high_corr_pairs = get_high_correlation_features(df_encoded, threshold=0.8)\\n',\n",
       "    '\\n',\n",
       "    'if len(high_corr_pairs) > 0:\\n',\n",
       "    '    print(f\"\\\\nFound {len(high_corr_pairs)} pairs of highly correlated features (>0.8):\")\\n',\n",
       "    '    for pair in high_corr_pairs[:10]:  # Show first 10\\n',\n",
       "    '        print(f\"  {pair[0]} <-> {pair[1]}: {pair[2]:.3f}\")\\n',\n",
       "    '    \\n',\n",
       "    '    print(\"\\\\n⚠️  Consider removing one feature from each highly correlated pair.\")\\n',\n",
       "    'else:\\n',\n",
       "    '    print(\"\\\\n✓ No high multicollinearity detected.\")']},\n",
       "  {'cell_type': 'markdown',\n",
       "   'metadata': {},\n",
       "   'source': ['## 7. Prepare Final Feature Set']},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': None,\n",
       "   'metadata': {},\n",
       "   'outputs': [],\n",
       "   'source': ['print(\"Preparing final feature set...\")\\n',\n",
       "    'print(\"=\"*60)\\n',\n",
       "    '\\n',\n",
       "    '# Option 1: Use all features\\n',\n",
       "    'features_all = X.columns.tolist()\\n',\n",
       "    '\\n',\n",
       "    '# Option 2: Use selected features (union of correlation and univariate)\\n',\n",
       "    'features_selected = list(set(selected_features_corr) | set(selected_features_univariate))\\n',\n",
       "    '\\n',\n",
       "    '# Option 3: Use top features from univariate selection\\n',\n",
       "    'features_top = selected_features_univariate\\n',\n",
       "    '\\n',\n",
       "    'print(f\"\\\\nFeature set options:\")\\n',\n",
       "    'print(f\"  1. All features: {len(features_all)} features\")\\n',\n",
       "    'print(f\"  2. Selected features (union): {len(features_selected)} features\")\\n',\n",
       "    'print(f\"  3. Top univariate features: {len(features_top)} features\")\\n',\n",
       "    '\\n',\n",
       "    \"# We'll use Option 1 (all features) and let the model do feature selection\\n\",\n",
       "    'final_features = features_all\\n',\n",
       "    '\\n',\n",
       "    'print(f\"\\\\n✓ Using all features for modeling: {len(final_features)} features\")']},\n",
       "  {'cell_type': 'markdown',\n",
       "   'metadata': {},\n",
       "   'source': ['## 8. Train-Test Split']},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': None,\n",
       "   'metadata': {},\n",
       "   'outputs': [],\n",
       "   'source': ['print(\"Splitting data into train and test sets...\")\\n',\n",
       "    'print(\"=\"*60)\\n',\n",
       "    '\\n',\n",
       "    'X_final = df_encoded[final_features]\\n',\n",
       "    \"y_final = df_encoded['heart_attack']\\n\",\n",
       "    '\\n',\n",
       "    'X_train, X_test, y_train, y_test = preprocessor.prepare_data_for_modeling(\\n',\n",
       "    \"    df_encoded[final_features + ['heart_attack']], \\n\",\n",
       "    \"    target_column='heart_attack',\\n\",\n",
       "    '    test_size=0.2,\\n',\n",
       "    '    random_state=42\\n',\n",
       "    ')\\n',\n",
       "    '\\n',\n",
       "    'print(f\"\\\\nTrain set: {X_train.shape}\")\\n',\n",
       "    'print(f\"Test set: {X_test.shape}\")']},\n",
       "  {'cell_type': 'markdown',\n",
       "   'metadata': {},\n",
       "   'source': ['## 9. Feature Scaling']},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': None,\n",
       "   'metadata': {},\n",
       "   'outputs': [],\n",
       "   'source': ['print(\"Scaling features...\")\\n',\n",
       "    'print(\"=\"*60)\\n',\n",
       "    '\\n',\n",
       "    '# Scale features\\n',\n",
       "    'X_train_scaled, X_test_scaled = preprocessor.scale_features(X_train, X_test)\\n',\n",
       "    '\\n',\n",
       "    '# Convert back to DataFrame for easier handling\\n',\n",
       "    'X_train_scaled = pd.DataFrame(X_train_scaled, columns=X_train.columns, index=X_train.index)\\n',\n",
       "    'X_test_scaled = pd.DataFrame(X_test_scaled, columns=X_test.columns, index=X_test.index)\\n',\n",
       "    '\\n',\n",
       "    'print(\"\\\\n✓ Features scaled successfully!\")\\n',\n",
       "    'print(f\"\\\\nScaled train set: {X_train_scaled.shape}\")\\n',\n",
       "    'print(f\"Scaled test set: {X_test_scaled.shape}\")\\n',\n",
       "    '\\n',\n",
       "    '# Check scaling\\n',\n",
       "    'print(\"\\\\nScaled data statistics (sample features):\")\\n',\n",
       "    \"print(X_train_scaled[['age', 'cholesterol_level', 'blood_pressure_systolic']].describe())\"]},\n",
       "  {'cell_type': 'markdown',\n",
       "   'metadata': {},\n",
       "   'source': ['## 10. Save Processed Data']},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': None,\n",
       "   'metadata': {},\n",
       "   'outputs': [],\n",
       "   'source': ['print(\"Saving processed datasets...\")\\n',\n",
       "    'print(\"=\"*60)\\n',\n",
       "    '\\n',\n",
       "    '# Save engineered features dataset\\n',\n",
       "    \"df_encoded.to_csv('../data/heart_attack_data_engineered.csv', index=False)\\n\",\n",
       "    'print(\"✓ Engineered dataset saved: heart_attack_data_engineered.csv\")\\n',\n",
       "    '\\n',\n",
       "    '# Save train/test splits\\n',\n",
       "    \"X_train_scaled.to_csv('../data/X_train_scaled.csv', index=False)\\n\",\n",
       "    \"X_test_scaled.to_csv('../data/X_test_scaled.csv', index=False)\\n\",\n",
       "    \"y_train.to_csv('../data/y_train.csv', index=False)\\n\",\n",
       "    \"y_test.to_csv('../data/y_test.csv', index=False)\\n\",\n",
       "    '\\n',\n",
       "    'print(\"✓ Train/test splits saved:\")\\n',\n",
       "    'print(\"  - X_train_scaled.csv\")\\n',\n",
       "    'print(\"  - X_test_scaled.csv\")\\n',\n",
       "    'print(\"  - y_train.csv\")\\n',\n",
       "    'print(\"  - y_test.csv\")\\n',\n",
       "    '\\n',\n",
       "    '# Save feature names\\n',\n",
       "    \"pd.DataFrame({'feature': final_features}).to_csv('../data/feature_names.csv', index=False)\\n\",\n",
       "    'print(\"✓ Feature names saved: feature_names.csv\")\\n',\n",
       "    '\\n',\n",
       "    '# Save preprocessor objects\\n',\n",
       "    'import joblib\\n',\n",
       "    \"joblib.dump(preprocessor.scaler, '../models/scaler.pkl')\\n\",\n",
       "    \"joblib.dump(preprocessor.label_encoders, '../models/label_encoders.pkl')\\n\",\n",
       "    'print(\"\\\\n✓ Preprocessor objects saved:\")\\n',\n",
       "    'print(\"  - scaler.pkl\")\\n',\n",
       "    'print(\"  - label_encoders.pkl\")']},\n",
       "  {'cell_type': 'markdown',\n",
       "   'metadata': {},\n",
       "   'source': ['## 11. Feature Engineering Report']},\n",
       "  {'cell_type': 'code',\n",
       "   'execution_count': None,\n",
       "   'metadata': {},\n",
       "   'outputs': [],\n",
       "   'source': ['print(\"\\\\n\" + \"=\"*60)\\n',\n",
       "    'print(\"FEATURE ENGINEERING SUMMARY REPORT\")\\n',\n",
       "    'print(\"=\"*60)\\n',\n",
       "    '\\n',\n",
       "    'print(f\"\\\\n1. DATASET TRANSFORMATION:\")\\n',\n",
       "    'print(f\"   Original features: {df.shape[1]}\")\\n',\n",
       "    'print(f\"   Engineered features: {df_encoded.shape[1]}\")\\n',\n",
       "    'print(f\"   New features created: {df_encoded.shape[1] - df.shape[1]}\")\\n',\n",
       "    '\\n',\n",
       "    'print(f\"\\\\n2. NEW FEATURES CREATED:\")\\n',\n",
       "    'new_features = set(df_encoded.columns) - set(df.columns)\\n',\n",
       "    'for i, feat in enumerate(sorted(new_features), 1):\\n',\n",
       "    '    print(f\"   {i:2d}. {feat}\")\\n',\n",
       "    '\\n',\n",
       "    'print(f\"\\\\n3. CATEGORICAL ENCODING:\")\\n',\n",
       "    'print(f\"   Encoded columns: {len(categorical_cols)}\")\\n',\n",
       "    'print(f\"   Encoding method: Label Encoding\")\\n',\n",
       "    '\\n',\n",
       "    'print(f\"\\\\n4. FEATURE SELECTION:\")\\n',\n",
       "    'print(f\"   Features by correlation (>{threshold}): {len(selected_features_corr)}\")\\n',\n",
       "    'print(f\"   Features by univariate test (top {k}): {len(selected_features_univariate)}\")\\n',\n",
       "    'print(f\"   Final features for modeling: {len(final_features)}\")\\n',\n",
       "    '\\n',\n",
       "    'print(f\"\\\\n5. DATA SPLIT:\")\\n',\n",
       "    'print(f\"   Training set: {X_train.shape[0]} samples ({X_train.shape[0]/len(df_encoded)*100:.1f}%)\")\\n',\n",
       "    'print(f\"   Test set: {X_test.shape[0]} samples ({X_test.shape[0]/len(df_encoded)*100:.1f}%)\")\\n',\n",
       "    '\\n',\n",
       "    'print(f\"\\\\n6. FEATURE SCALING:\")\\n',\n",
       "    'print(f\"   Scaling method: StandardScaler (z-score normalization)\")\\n',\n",
       "    'print(f\"   Scaled features: All numerical features\")\\n',\n",
       "    '\\n',\n",
       "    'print(f\"\\\\n7. TOP FEATURES (by correlation with target):\")\\n',\n",
       "    'top_5 = correlations.head(5)\\n',\n",
       "    'for i, (feat, corr) in enumerate(top_5.items(), 1):\\n',\n",
       "    '    print(f\"   {i}. {feat:30s}: {corr:+.4f}\")\\n',\n",
       "    '\\n',\n",
       "    'print(f\"\\\\n8. FILES SAVED:\")\\n',\n",
       "    'print(f\"   - heart_attack_data_engineered.csv (Full dataset with engineered features)\")\\n',\n",
       "    'print(f\"   - X_train_scaled.csv, X_test_scaled.csv (Scaled features)\")\\n',\n",
       "    'print(f\"   - y_train.csv, y_test.csv (Target variables)\")\\n',\n",
       "    'print(f\"   - feature_names.csv (List of features)\")\\n',\n",
       "    'print(f\"   - scaler.pkl, label_encoders.pkl (Preprocessing objects)\")\\n',\n",
       "    '\\n',\n",
       "    'print(\"\\\\n\" + \"=\"*60)\\n',\n",
       "    'print(\"✓ Feature Engineering Completed Successfully!\")\\n',\n",
       "    'print(\"=\"*60)']},\n",
       "  {'cell_type': 'markdown',\n",
       "   'metadata': {},\n",
       "   'source': ['## Summary\\n',\n",
       "    '\\n',\n",
       "    'Pada tahap Feature Engineering ini, kita telah:\\n',\n",
       "    '\\n',\n",
       "    '1. ✅ **Created New Features**:\\n',\n",
       "    '   - Age groups (categorical)\\n',\n",
       "    '   - Blood pressure categories\\n',\n",
       "    '   - Cholesterol categories\\n',\n",
       "    '   - BMI categories\\n',\n",
       "    '   - Composite risk score\\n',\n",
       "    '   - Interaction features (age × conditions, BP interactions, etc.)\\n',\n",
       "    '\\n',\n",
       "    '2. ✅ **Encoded Categorical Variables**:\\n',\n",
       "    '   - Label encoding untuk semua categorical features\\n',\n",
       "    '   - Preserved label encoders untuk future use\\n',\n",
       "    '\\n',\n",
       "    '3. ✅ **Feature Selection**:\\n',\n",
       "    '   - Correlation-based selection\\n',\n",
       "    '   - Univariate statistical tests\\n',\n",
       "    '   - Multicollinearity check\\n',\n",
       "    '\\n',\n",
       "    '4. ✅ **Data Preparation**:\\n',\n",
       "    '   - Train-test split (80-20)\\n',\n",
       "    '   - Feature scaling (StandardScaler)\\n',\n",
       "    '   - Stratified sampling untuk balanced classes\\n',\n",
       "    '\\n',\n",
       "    '5. ✅ **Saved Artifacts**:\\n',\n",
       "    '   - Processed datasets\\n',\n",
       "    '   - Preprocessing objects\\n',\n",
       "    '   - Feature names\\n',\n",
       "    '\\n',\n",
       "    '### Key Achievements:\\n',\n",
       "    '- Increased feature space dengan meaningful engineered features\\n',\n",
       "    '- Maintained interpretability of features\\n',\n",
       "    '- Prepared clean, scaled data ready for modeling\\n',\n",
       "    '- Created reusable preprocessing pipeline\\n',\n",
       "    '\\n',\n",
       "    '### Feature Quality:\\n',\n",
       "    '- All features properly encoded\\n',\n",
       "    '- No missing values\\n',\n",
       "    '- Scaled for consistent ranges\\n',\n",
       "    '- Low multicollinearity\\n',\n",
       "    '\\n',\n",
       "    '### Next Steps:\\n',\n",
       "    'Lanjut ke **Notebook 6: Predictive Modeling** untuk train machine learning models.\\n',\n",
       "    '\\n',\n",
       "    '---']}],\n",
       " 'metadata': {'kernelspec': {'display_name': 'Python 3',\n",
       "   'language': 'python',\n",
       "   'name': 'python3'},\n",
       "  'language_info': {'codemirror_mode': {'name': 'ipython', 'version': 3},\n",
       "   'file_extension': '.py',\n",
       "   'mimetype': 'text/x-python',\n",
       "   'name': 'python',\n",
       "   'nbconvert_exporter': 'python',\n",
       "   'pygments_lexer': 'ipython3',\n",
       "   'version': '3.9.0'}},\n",
       " 'nbformat': 4,\n",
       " 'nbformat_minor': 4}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{\n",
    " \"cells\": [\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Indonesia Heart Attack Prediction\\n\",\n",
    "    \"## Notebook 5: Feature Engineering\\n\",\n",
    "    \"\\n\",\n",
    "    \"---\\n\",\n",
    "    \"\\n\",\n",
    "    \"### Tahap 5 dari Data Science Life Cycle\\n\",\n",
    "    \"\\n\",\n",
    "    \"Pada tahap ini, kita akan:\\n\",\n",
    "    \"1. Create new features dari existing features\\n\",\n",
    "    \"2. Transform features untuk improve model performance\\n\",\n",
    "    \"3. Select important features\\n\",\n",
    "    \"4. Encode categorical variables\\n\",\n",
    "    \"5. Scale numerical features\\n\",\n",
    "    \"6. Prepare final dataset untuk modeling\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 1. Import Libraries dan Load Data\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": None,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Data manipulation\\n\",\n",
    "    \"import pandas as pd\\n\",\n",
    "    \"import numpy as np\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Visualization\\n\",\n",
    "    \"import matplotlib.pyplot as plt\\n\",\n",
    "    \"import seaborn as sns\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Feature engineering and selection\\n\",\n",
    "    \"from sklearn.preprocessing import LabelEncoder, StandardScaler\\n\",\n",
    "    \"from sklearn.feature_selection import SelectKBest, chi2, f_classif, mutual_info_classif\\n\",\n",
    "    \"\\n\",\n",
    "    \"# System utilities\\n\",\n",
    "    \"import sys\\n\",\n",
    "    \"sys.path.append('../src')\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Import custom modules\\n\",\n",
    "    \"from feature_engineering import FeatureEngineer, get_high_correlation_features, feature_summary\\n\",\n",
    "    \"from data_preprocessing import DataPreprocessor\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Settings\\n\",\n",
    "    \"pd.set_option('display.max_columns', None)\\n\",\n",
    "    \"plt.style.use('seaborn-v0_8-whitegrid')\\n\",\n",
    "    \"sns.set_palette('husl')\\n\",\n",
    "    \"\\n\",\n",
    "    \"import warnings\\n\",\n",
    "    \"warnings.filterwarnings('ignore')\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"Libraries imported successfully!\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": None,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Load cleaned data\\n\",\n",
    "    \"df = pd.read_csv('../data/heart_attack_data_cleaned.csv')\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"Original dataset shape: {df.shape}\\\")\\n\",\n",
    "    \"print(f\\\"Features: {df.shape[1]}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Initialize feature engineer\\n\",\n",
    "    \"fe = FeatureEngineer()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 2. Create New Features\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"### 2.1 Age-based Features\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": None,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"print(\\\"Creating age-based features...\\\")\\n\",\n",
    "    \"print(\\\"=\\\"*60)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Age groups\\n\",\n",
    "    \"df_engineered = fe.create_age_groups(df)\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"\\\\nAge groups created:\\\")\\n\",\n",
    "    \"print(df_engineered['age_group'].value_counts().sort_index())\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"### 2.2 Blood Pressure Categories\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": None,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"print(\\\"Creating blood pressure categories...\\\")\\n\",\n",
    "    \"print(\\\"=\\\"*60)\\n\",\n",
    "    \"\\n\",\n",
    "    \"df_engineered = fe.create_blood_pressure_category(df_engineered)\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"\\\\nBlood pressure categories:\\\")\\n\",\n",
    "    \"print(df_engineered['bp_category'].value_counts())\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"### 2.3 Cholesterol Categories\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": None,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"print(\\\"Creating cholesterol categories...\\\")\\n\",\n",
    "    \"print(\\\"=\\\"*60)\\n\",\n",
    "    \"\\n\",\n",
    "    \"df_engineered = fe.create_cholesterol_category(df_engineered)\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"\\\\nCholesterol categories:\\\")\\n\",\n",
    "    \"print(df_engineered['cholesterol_category'].value_counts())\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"### 2.4 BMI Category\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": None,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"print(\\\"Creating BMI categories...\\\")\\n\",\n",
    "    \"print(\\\"=\\\"*60)\\n\",\n",
    "    \"\\n\",\n",
    "    \"df_engineered = fe.create_bmi_category(df_engineered)\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"\\\\nBMI categories:\\\")\\n\",\n",
    "    \"print(df_engineered['bmi_category'].value_counts())\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"### 2.5 Risk Score (Composite Feature)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": None,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"print(\\\"Creating composite risk score...\\\")\\n\",\n",
    "    \"print(\\\"=\\\"*60)\\n\",\n",
    "    \"\\n\",\n",
    "    \"df_engineered = fe.create_risk_score(df_engineered)\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"\\\\nRisk score statistics:\\\")\\n\",\n",
    "    \"print(df_engineered['risk_score'].describe())\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Visualize risk score distribution\\n\",\n",
    "    \"fig, axes = plt.subplots(1, 2, figsize=(14, 5))\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Distribution\\n\",\n",
    "    \"df_engineered['risk_score'].hist(bins=15, ax=axes[0], color='steelblue', edgecolor='black')\\n\",\n",
    "    \"axes[0].set_title('Risk Score Distribution', fontsize=12, fontweight='bold')\\n\",\n",
    "    \"axes[0].set_xlabel('Risk Score')\\n\",\n",
    "    \"axes[0].set_ylabel('Frequency')\\n\",\n",
    "    \"axes[0].axvline(df_engineered['risk_score'].mean(), color='red', linestyle='--',\\n\",\n",
    "    \"               label=f'Mean: {df_engineered[\\\"risk_score\\\"].mean():.2f}')\\n\",\n",
    "    \"axes[0].legend()\\n\",\n",
    "    \"axes[0].grid(alpha=0.3)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Risk score vs heart attack\\n\",\n",
    "    \"df_engineered.boxplot(column='risk_score', by='heart_attack', ax=axes[1])\\n\",\n",
    "    \"axes[1].set_title('Risk Score by Heart Attack Status')\\n\",\n",
    "    \"axes[1].set_xlabel('Heart Attack')\\n\",\n",
    "    \"axes[1].set_ylabel('Risk Score')\\n\",\n",
    "    \"axes[1].set_xticklabels(['No', 'Yes'])\\n\",\n",
    "    \"plt.sca(axes[1])\\n\",\n",
    "    \"plt.xticks([1, 2], ['No', 'Yes'])\\n\",\n",
    "    \"\\n\",\n",
    "    \"plt.tight_layout()\\n\",\n",
    "    \"plt.show()\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Calculate mean risk score by heart attack status\\n\",\n",
    "    \"print(\\\"\\\\nMean risk score by heart attack status:\\\")\\n\",\n",
    "    \"print(df_engineered.groupby('heart_attack')['risk_score'].mean())\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"### 2.6 Interaction Features\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": None,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"print(\\\"Creating interaction features...\\\")\\n\",\n",
    "    \"print(\\\"=\\\"*60)\\n\",\n",
    "    \"\\n\",\n",
    "    \"df_engineered = fe.create_interaction_features(df_engineered)\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"\\\\nNew interaction features created:\\\")\\n\",\n",
    "    \"interaction_features = ['age_hypertension', 'age_diabetes', 'cholesterol_age', \\n\",\n",
    "    \"                       'bp_interaction', 'total_health_conditions']\\n\",\n",
    "    \"for feat in interaction_features:\\n\",\n",
    "    \"    if feat in df_engineered.columns:\\n\",\n",
    "    \"        print(f\\\"  - {feat}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 3. Feature Engineering Summary\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": None,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"print(\\\"Feature Engineering Summary:\\\")\\n\",\n",
    "    \"print(\\\"=\\\"*60)\\n\",\n",
    "    \"\\n\",\n",
    "    \"summary = feature_summary(df, df_engineered)\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"\\\\nOriginal features: {summary['original_features']}\\\")\\n\",\n",
    "    \"print(f\\\"Engineered features: {summary['engineered_features']}\\\")\\n\",\n",
    "    \"print(f\\\"New features created: {summary['new_features_count']}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"\\\\nList of new features:\\\")\\n\",\n",
    "    \"for i, feat in enumerate(summary['new_features_list'], 1):\\n\",\n",
    "    \"    print(f\\\"  {i}. {feat}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 4. Encode Categorical Variables\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": None,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"print(\\\"Encoding categorical variables...\\\")\\n\",\n",
    "    \"print(\\\"=\\\"*60)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Identify categorical columns\\n\",\n",
    "    \"categorical_cols = df_engineered.select_dtypes(include=['object']).columns.tolist()\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"\\\\nCategorical columns to encode: {len(categorical_cols)}\\\")\\n\",\n",
    "    \"for col in categorical_cols:\\n\",\n",
    "    \"    print(f\\\"  - {col}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Initialize preprocessor for encoding\\n\",\n",
    "    \"preprocessor = DataPreprocessor()\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Encode categorical variables\\n\",\n",
    "    \"df_encoded = preprocessor.encode_categorical(df_engineered, categorical_cols)\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"\\\\n✓ Categorical variables encoded successfully!\\\")\\n\",\n",
    "    \"print(f\\\"\\\\nDataset shape after encoding: {df_encoded.shape}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 5. Feature Correlation Analysis\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": None,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"print(\\\"Analyzing feature correlations with target...\\\")\\n\",\n",
    "    \"print(\\\"=\\\"*60)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Calculate correlation with heart_attack\\n\",\n",
    "    \"correlations = df_encoded.corr()['heart_attack'].drop('heart_attack').sort_values(ascending=False)\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"\\\\nTop 20 features correlated with Heart Attack:\\\")\\n\",\n",
    "    \"print(correlations.head(20))\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Visualize top correlations\\n\",\n",
    "    \"plt.figure(figsize=(12, 10))\\n\",\n",
    "    \"top_n = 20\\n\",\n",
    "    \"top_corr = correlations.head(top_n)\\n\",\n",
    "    \"colors = ['green' if x > 0 else 'red' for x in top_corr]\\n\",\n",
    "    \"\\n\",\n",
    "    \"plt.barh(range(len(top_corr)), top_corr.values, color=colors)\\n\",\n",
    "    \"plt.yticks(range(len(top_corr)), top_corr.index)\\n\",\n",
    "    \"plt.xlabel('Correlation Coefficient', fontsize=12)\\n\",\n",
    "    \"plt.title(f'Top {top_n} Features Correlated with Heart Attack', fontsize=14, fontweight='bold')\\n\",\n",
    "    \"plt.axvline(x=0, color='black', linestyle='--', linewidth=0.8)\\n\",\n",
    "    \"plt.grid(axis='x', alpha=0.3)\\n\",\n",
    "    \"plt.tight_layout()\\n\",\n",
    "    \"plt.show()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 6. Feature Selection\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"### 6.1 Correlation-based Feature Selection\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": None,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"print(\\\"Correlation-based Feature Selection:\\\")\\n\",\n",
    "    \"print(\\\"=\\\"*60)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Select features with correlation > threshold\\n\",\n",
    "    \"threshold = 0.05\\n\",\n",
    "    \"selected_features_corr = fe.select_features_correlation(df_encoded, 'heart_attack', threshold=threshold)\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"\\\\nFeatures selected (correlation > {threshold}): {len(selected_features_corr)}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"### 6.2 Univariate Feature Selection\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": None,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"print(\\\"Univariate Feature Selection:\\\")\\n\",\n",
    "    \"print(\\\"=\\\"*60)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Prepare X and y\\n\",\n",
    "    \"X = df_encoded.drop('heart_attack', axis=1)\\n\",\n",
    "    \"y = df_encoded['heart_attack']\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Select top K features using f_classif\\n\",\n",
    "    \"k = 20\\n\",\n",
    "    \"selected_features_univariate, selector = fe.select_features_univariate(X, y, k=k, score_func='f_classif')\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"\\\\nTop {k} features selected.\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"### 6.3 Check Multicollinearity\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": None,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"print(\\\"Checking for multicollinearity...\\\")\\n\",\n",
    "    \"print(\\\"=\\\"*60)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Find highly correlated features\\n\",\n",
    "    \"high_corr_pairs = get_high_correlation_features(df_encoded, threshold=0.8)\\n\",\n",
    "    \"\\n\",\n",
    "    \"if len(high_corr_pairs) > 0:\\n\",\n",
    "    \"    print(f\\\"\\\\nFound {len(high_corr_pairs)} pairs of highly correlated features (>0.8):\\\")\\n\",\n",
    "    \"    for pair in high_corr_pairs[:10]:  # Show first 10\\n\",\n",
    "    \"        print(f\\\"  {pair[0]} <-> {pair[1]}: {pair[2]:.3f}\\\")\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    print(\\\"\\\\n⚠️  Consider removing one feature from each highly correlated pair.\\\")\\n\",\n",
    "    \"else:\\n\",\n",
    "    \"    print(\\\"\\\\n✓ No high multicollinearity detected.\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 7. Prepare Final Feature Set\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": None,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"print(\\\"Preparing final feature set...\\\")\\n\",\n",
    "    \"print(\\\"=\\\"*60)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Option 1: Use all features\\n\",\n",
    "    \"features_all = X.columns.tolist()\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Option 2: Use selected features (union of correlation and univariate)\\n\",\n",
    "    \"features_selected = list(set(selected_features_corr) | set(selected_features_univariate))\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Option 3: Use top features from univariate selection\\n\",\n",
    "    \"features_top = selected_features_univariate\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"\\\\nFeature set options:\\\")\\n\",\n",
    "    \"print(f\\\"  1. All features: {len(features_all)} features\\\")\\n\",\n",
    "    \"print(f\\\"  2. Selected features (union): {len(features_selected)} features\\\")\\n\",\n",
    "    \"print(f\\\"  3. Top univariate features: {len(features_top)} features\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# We'll use Option 1 (all features) and let the model do feature selection\\n\",\n",
    "    \"final_features = features_all\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"\\\\n✓ Using all features for modeling: {len(final_features)} features\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 8. Train-Test Split\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": None,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"print(\\\"Splitting data into train and test sets...\\\")\\n\",\n",
    "    \"print(\\\"=\\\"*60)\\n\",\n",
    "    \"\\n\",\n",
    "    \"X_final = df_encoded[final_features]\\n\",\n",
    "    \"y_final = df_encoded['heart_attack']\\n\",\n",
    "    \"\\n\",\n",
    "    \"X_train, X_test, y_train, y_test = preprocessor.prepare_data_for_modeling(\\n\",\n",
    "    \"    df_encoded[final_features + ['heart_attack']], \\n\",\n",
    "    \"    target_column='heart_attack',\\n\",\n",
    "    \"    test_size=0.2,\\n\",\n",
    "    \"    random_state=42\\n\",\n",
    "    \")\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"\\\\nTrain set: {X_train.shape}\\\")\\n\",\n",
    "    \"print(f\\\"Test set: {X_test.shape}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 9. Feature Scaling\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": None,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"print(\\\"Scaling features...\\\")\\n\",\n",
    "    \"print(\\\"=\\\"*60)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Scale features\\n\",\n",
    "    \"X_train_scaled, X_test_scaled = preprocessor.scale_features(X_train, X_test)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Convert back to DataFrame for easier handling\\n\",\n",
    "    \"X_train_scaled = pd.DataFrame(X_train_scaled, columns=X_train.columns, index=X_train.index)\\n\",\n",
    "    \"X_test_scaled = pd.DataFrame(X_test_scaled, columns=X_test.columns, index=X_test.index)\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"\\\\n✓ Features scaled successfully!\\\")\\n\",\n",
    "    \"print(f\\\"\\\\nScaled train set: {X_train_scaled.shape}\\\")\\n\",\n",
    "    \"print(f\\\"Scaled test set: {X_test_scaled.shape}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Check scaling\\n\",\n",
    "    \"print(\\\"\\\\nScaled data statistics (sample features):\\\")\\n\",\n",
    "    \"print(X_train_scaled[['age', 'cholesterol_level', 'blood_pressure_systolic']].describe())\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 10. Save Processed Data\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": None,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"print(\\\"Saving processed datasets...\\\")\\n\",\n",
    "    \"print(\\\"=\\\"*60)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Save engineered features dataset\\n\",\n",
    "    \"df_encoded.to_csv('../data/heart_attack_data_engineered.csv', index=False)\\n\",\n",
    "    \"print(\\\"✓ Engineered dataset saved: heart_attack_data_engineered.csv\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Save train/test splits\\n\",\n",
    "    \"X_train_scaled.to_csv('../data/X_train_scaled.csv', index=False)\\n\",\n",
    "    \"X_test_scaled.to_csv('../data/X_test_scaled.csv', index=False)\\n\",\n",
    "    \"y_train.to_csv('../data/y_train.csv', index=False)\\n\",\n",
    "    \"y_test.to_csv('../data/y_test.csv', index=False)\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"✓ Train/test splits saved:\\\")\\n\",\n",
    "    \"print(\\\"  - X_train_scaled.csv\\\")\\n\",\n",
    "    \"print(\\\"  - X_test_scaled.csv\\\")\\n\",\n",
    "    \"print(\\\"  - y_train.csv\\\")\\n\",\n",
    "    \"print(\\\"  - y_test.csv\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Save feature names\\n\",\n",
    "    \"pd.DataFrame({'feature': final_features}).to_csv('../data/feature_names.csv', index=False)\\n\",\n",
    "    \"print(\\\"✓ Feature names saved: feature_names.csv\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Save preprocessor objects\\n\",\n",
    "    \"import joblib\\n\",\n",
    "    \"joblib.dump(preprocessor.scaler, '../models/scaler.pkl')\\n\",\n",
    "    \"joblib.dump(preprocessor.label_encoders, '../models/label_encoders.pkl')\\n\",\n",
    "    \"print(\\\"\\\\n✓ Preprocessor objects saved:\\\")\\n\",\n",
    "    \"print(\\\"  - scaler.pkl\\\")\\n\",\n",
    "    \"print(\\\"  - label_encoders.pkl\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 11. Feature Engineering Report\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": None,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"print(\\\"\\\\n\\\" + \\\"=\\\"*60)\\n\",\n",
    "    \"print(\\\"FEATURE ENGINEERING SUMMARY REPORT\\\")\\n\",\n",
    "    \"print(\\\"=\\\"*60)\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"\\\\n1. DATASET TRANSFORMATION:\\\")\\n\",\n",
    "    \"print(f\\\"   Original features: {df.shape[1]}\\\")\\n\",\n",
    "    \"print(f\\\"   Engineered features: {df_encoded.shape[1]}\\\")\\n\",\n",
    "    \"print(f\\\"   New features created: {df_encoded.shape[1] - df.shape[1]}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"\\\\n2. NEW FEATURES CREATED:\\\")\\n\",\n",
    "    \"new_features = set(df_encoded.columns) - set(df.columns)\\n\",\n",
    "    \"for i, feat in enumerate(sorted(new_features), 1):\\n\",\n",
    "    \"    print(f\\\"   {i:2d}. {feat}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"\\\\n3. CATEGORICAL ENCODING:\\\")\\n\",\n",
    "    \"print(f\\\"   Encoded columns: {len(categorical_cols)}\\\")\\n\",\n",
    "    \"print(f\\\"   Encoding method: Label Encoding\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"\\\\n4. FEATURE SELECTION:\\\")\\n\",\n",
    "    \"print(f\\\"   Features by correlation (>{threshold}): {len(selected_features_corr)}\\\")\\n\",\n",
    "    \"print(f\\\"   Features by univariate test (top {k}): {len(selected_features_univariate)}\\\")\\n\",\n",
    "    \"print(f\\\"   Final features for modeling: {len(final_features)}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"\\\\n5. DATA SPLIT:\\\")\\n\",\n",
    "    \"print(f\\\"   Training set: {X_train.shape[0]} samples ({X_train.shape[0]/len(df_encoded)*100:.1f}%)\\\")\\n\",\n",
    "    \"print(f\\\"   Test set: {X_test.shape[0]} samples ({X_test.shape[0]/len(df_encoded)*100:.1f}%)\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"\\\\n6. FEATURE SCALING:\\\")\\n\",\n",
    "    \"print(f\\\"   Scaling method: StandardScaler (z-score normalization)\\\")\\n\",\n",
    "    \"print(f\\\"   Scaled features: All numerical features\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"\\\\n7. TOP FEATURES (by correlation with target):\\\")\\n\",\n",
    "    \"top_5 = correlations.head(5)\\n\",\n",
    "    \"for i, (feat, corr) in enumerate(top_5.items(), 1):\\n\",\n",
    "    \"    print(f\\\"   {i}. {feat:30s}: {corr:+.4f}\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"\\\\n8. FILES SAVED:\\\")\\n\",\n",
    "    \"print(f\\\"   - heart_attack_data_engineered.csv (Full dataset with engineered features)\\\")\\n\",\n",
    "    \"print(f\\\"   - X_train_scaled.csv, X_test_scaled.csv (Scaled features)\\\")\\n\",\n",
    "    \"print(f\\\"   - y_train.csv, y_test.csv (Target variables)\\\")\\n\",\n",
    "    \"print(f\\\"   - feature_names.csv (List of features)\\\")\\n\",\n",
    "    \"print(f\\\"   - scaler.pkl, label_encoders.pkl (Preprocessing objects)\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"\\\\n\\\" + \\\"=\\\"*60)\\n\",\n",
    "    \"print(\\\"✓ Feature Engineering Completed Successfully!\\\")\\n\",\n",
    "    \"print(\\\"=\\\"*60)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## Summary\\n\",\n",
    "    \"\\n\",\n",
    "    \"Pada tahap Feature Engineering ini, kita telah:\\n\",\n",
    "    \"\\n\",\n",
    "    \"1. ✅ **Created New Features**:\\n\",\n",
    "    \"   - Age groups (categorical)\\n\",\n",
    "    \"   - Blood pressure categories\\n\",\n",
    "    \"   - Cholesterol categories\\n\",\n",
    "    \"   - BMI categories\\n\",\n",
    "    \"   - Composite risk score\\n\",\n",
    "    \"   - Interaction features (age × conditions, BP interactions, etc.)\\n\",\n",
    "    \"\\n\",\n",
    "    \"2. ✅ **Encoded Categorical Variables**:\\n\",\n",
    "    \"   - Label encoding untuk semua categorical features\\n\",\n",
    "    \"   - Preserved label encoders untuk future use\\n\",\n",
    "    \"\\n\",\n",
    "    \"3. ✅ **Feature Selection**:\\n\",\n",
    "    \"   - Correlation-based selection\\n\",\n",
    "    \"   - Univariate statistical tests\\n\",\n",
    "    \"   - Multicollinearity check\\n\",\n",
    "    \"\\n\",\n",
    "    \"4. ✅ **Data Preparation**:\\n\",\n",
    "    \"   - Train-test split (80-20)\\n\",\n",
    "    \"   - Feature scaling (StandardScaler)\\n\",\n",
    "    \"   - Stratified sampling untuk balanced classes\\n\",\n",
    "    \"\\n\",\n",
    "    \"5. ✅ **Saved Artifacts**:\\n\",\n",
    "    \"   - Processed datasets\\n\",\n",
    "    \"   - Preprocessing objects\\n\",\n",
    "    \"   - Feature names\\n\",\n",
    "    \"\\n\",\n",
    "    \"### Key Achievements:\\n\",\n",
    "    \"- Increased feature space dengan meaningful engineered features\\n\",\n",
    "    \"- Maintained interpretability of features\\n\",\n",
    "    \"- Prepared clean, scaled data ready for modeling\\n\",\n",
    "    \"- Created reusable preprocessing pipeline\\n\",\n",
    "    \"\\n\",\n",
    "    \"### Feature Quality:\\n\",\n",
    "    \"- All features properly encoded\\n\",\n",
    "    \"- No missing values\\n\",\n",
    "    \"- Scaled for consistent ranges\\n\",\n",
    "    \"- Low multicollinearity\\n\",\n",
    "    \"\\n\",\n",
    "    \"### Next Steps:\\n\",\n",
    "    \"Lanjut ke **Notebook 6: Predictive Modeling** untuk train machine learning models.\\n\",\n",
    "    \"\\n\",\n",
    "    \"---\"\n",
    "   ]\n",
    "  }\n",
    " ],\n",
    " \"metadata\": {\n",
    "  \"kernelspec\": {\n",
    "   \"display_name\": \"Python 3\",\n",
    "   \"language\": \"python\",\n",
    "   \"name\": \"python3\"\n",
    "  },\n",
    "  \"language_info\": {\n",
    "   \"codemirror_mode\": {\n",
    "    \"name\": \"ipython\",\n",
    "    \"version\": 3\n",
    "   },\n",
    "   \"file_extension\": \".py\",\n",
    "   \"mimetype\": \"text/x-python\",\n",
    "   \"name\": \"python\",\n",
    "   \"nbconvert_exporter\": \"python\",\n",
    "   \"pygments_lexer\": \"ipython3\",\n",
    "   \"version\": \"3.9.0\"\n",
    "  }\n",
    " },\n",
    " \"nbformat\": 4,\n",
    " \"nbformat_minor\": 4\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63210637-5e3d-44bb-a531-939af5f442f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
